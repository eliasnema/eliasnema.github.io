<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>ELIAS NEMA</title>
<link>https://www.eliasnema.com/index.html#category=newsletter</link>
<atom:link href="https://www.eliasnema.com/index-newsletter.xml" rel="self" type="application/rss+xml"/>
<description>Making data work: analytics, personalisation, relevance and recommender systems - whatever is takes.</description>
<generator>quarto-1.1.251</generator>
<lastBuildDate>Mon, 05 Oct 2020 23:00:00 GMT</lastBuildDate>
<item>
  <title>üìú History (of Data Platforms and Apps)</title>
  <dc:creator>Elias Nema</dc:creator>
  <link>https://www.eliasnema.com/posts/newsletter/2020-10-06-newsletter-data-platforms.html</link>
  <description><![CDATA[ 




<section id="history-of-data-platforms-and-apps" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="history-of-data-platforms-and-apps">History (of Data Platforms and Apps)</h2>
<p>What‚Äôs the history of data-intensive applications and how did we end in a state where machines can classify cats better than us?</p>
<section id="softhardware-history-through-the-lens-of-ai" class="level3">
<h3 class="anchored" data-anchor-id="softhardware-history-through-the-lens-of-ai">[Soft/Hard]ware History through the Lens of AI</h3>
<p>An <a href="https://hardwarelottery.github.io/">interesting take at</a> a hardware-software intersection through the lens of AI applications. Some things that I found particularly fascinating:</p>
<blockquote class="blockquote">
<p>This essay begins by acknowledging a crucial paradox: machine learning researchers mostly ignore hardware despite the role it plays in determining what ideas succeed.</p>
</blockquote>
<ul>
<li>Computing started with <strong>single-purpose</strong> machines.</li>
<li>Then, in 1969, the general-purpose era began. This meant any move for the application-specific hardware was economically unfeasible because the <strong>performance benefit would fade away</strong> within 1-2 years with an ever-increasing number of transistors.</li>
</ul>
<blockquote class="blockquote">
<p>The few attempts to deviate and produce specialized supercomputers for research were financially unsustainable and short-lived.</p>
</blockquote>
<ul>
<li>However, there was a silver lining for specialized hardware. <strong>Von Neumann Bottleneck</strong> ‚Äî the available compute is restricted by ‚Äúthe lone channel between the CPU and memory along which data has to travel sequentially‚Äù. Hence, in the 2000s GPUs were repurposed to be used with ML applications.</li>
<li>In 2012 Google <a href="https://arxiv.org/abs/1112.6209">used <strong>16,000 CPU cores to classify cats</strong></a>. In a year, the same task <a href="http://proceedings.mlr.press/v28/coates13.html">was completed with only <strong>2 CPU cores and 4 GPUs</strong></a>.</li>
<li>Hardware is only economically viable if the lifetime of the use case <strong>lasts more than three years</strong>. Hence, it already makes sense to build specific hardware for matrix multiplication for quite some time. Next come the unstructured sparsity and weight-specific quantization (what GPU manufacturers <a href="https://developer.nvidia.com/blog/nvidia-ampere-architecture-in-depth/">are recently doing</a>).</li>
<li>The rate of return for additional parameters is decreasing (e.g.&nbsp;Inception V3/ V4: <strong>21.8 vs 41.1 million parameters, 78.8 vs 80 % accuracy</strong>).</li>
<li>The training costs of GPT-3 is estimated to exceed <strong>$12 million dollars.</strong></li>
</ul>
</section>
<section id="a-brief-history-of-machine-learning-platforms" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="a-brief-history-of-machine-learning-platforms">A Brief History of Machine Learning Platforms</h3>
<p>No Hadoop, no AWS ‚Äî barbarian days. Check out the <a href="https://databaseline.tech/a-brief-history-of-ml-platforms/">full timeline here</a>, it‚Äôs quite fun.</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="https://www.eliasnema.com/posts/newsletter/2020-10-06-ml-history-start.png" class="figure-img" width="300"></p>
<p></p><figcaption class="figure-caption margin-caption">Pre-cloud Timeline</figcaption><p></p>
</figure>
</div>
</section>
<section id="is-data-hype-real" class="level3">
<h3 class="anchored" data-anchor-id="is-data-hype-real">Is Data Hype Real</h3>
<p><a href="https://medium.com/northzone/unpacking-the-data-hype-8c3a0ae63564">Another article</a> looking at different branches developed in a field of modern data processing. Describes prominent players in areas of data pipelines, catalogs, collaboration and quality.</p>
<blockquote class="blockquote">
<p><em>In 2010, the number of large enterprises with a Chief Data Officer (CDO) was 15. By&nbsp;<a href="https://medium.com/datapace/the-number-of-chief-data-officer-is-rising-but-this-role-is-still-unclear-be6add07315b">2017, it was up to 4,000</a>. In 2020, it‚Äôll be over 10,000. Why? Data is revenue and revenue is sexy.</em></p>
</blockquote>
</section>
<section id="state-of-ai" class="level3">
<h3 class="anchored" data-anchor-id="state-of-ai">State of AI</h3>
<p>Yearly <a href="https://www.stateof.ai/">state of the AI report</a>. Here are some excerpts from the executive summary (page 7 of the report):</p>
<ul>
<li>The hottest area in AI: still <strong>NLP</strong></li>
<li>Closed AI ‚Äî only <strong>15%</strong> of papers publish their code</li>
<li>Biology starts to benefit from AI (the <strong>first AI discovered drug</strong>)</li>
<li>Corporate-driven academic <strong>brain drain</strong></li>
<li><strong>US and China</strong> lead the AI research</li>
<li>Specialized hardware investments (see the hardware lottery article above). <strong>Semiconductor companies</strong> become more and more important.</li>
<li>Two <strong>wrong arrests</strong> using facial recognition.</li>
</ul>
</section>
</section>
<section id="ml-ops" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="ml-ops">ML Ops</h2>
<p>One of the hottest buzzwords in a room. However, I believe, this (and not the mysterious ML platforms) will <strong>close the gap in the adoption of ML applications and bring the power of data to the rest of us.</strong></p>
<section id="microsoft" class="level3">
<h3 class="anchored" data-anchor-id="microsoft">Microsoft</h3>
<p>Microsoft continues to do an amazing job for the ML community. Now with the GitHub as well. There is a <a href="https://github.blog/2020-10-01-keeping-your-data-pipelines-healthy-with-the-great-expectations-github-action/">second part</a> (<a href="https://github.blog/2020-06-17-using-github-actions-for-mlops-data-science/">part 1</a>) of the series related to the ML Ops ‚Äî what data ops should have become. Integration with github actions is amazing and now supports The Great Expectations <a href="https://github.com/marketplace/actions/great-expectations-data">action</a> (which is an awesome <a href="https://greatexpectations.io/">project</a> in itself). &gt; <em>GitHub Actions don‚Äôt just do CI/CD, they provide powerful and flexible automation for ML engineers and data scientists.</em></p>
</section>
<section id="whylogs" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="whylogs">WhyLogs</h3>
<p>Much of the difficulty in maintaining an ML system comes from data drift. <a href="https://medium.com/whylabs/whylogs-embrace-data-logging-a9449cd121d">WhyLogs</a> calculates approximate statistics for datasets of any size up to TB-scale. Available in both Python and Java.</p>
<p>Here is a data distribution over time from the <a href="https://www.notion.so/771525fbe58c4151a79e8711a99f0fab">example</a> walkthrough:</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="https://www.eliasnema.com/posts/newsletter/2020-10-06-why-logs.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption margin-caption">why-logs</figcaption><p></p>
</figure>
</div>


</section>
</section>

 ]]></description>
  <category>newsletter</category>
  <guid>https://www.eliasnema.com/posts/newsletter/2020-10-06-newsletter-data-platforms.html</guid>
  <pubDate>Mon, 05 Oct 2020 23:00:00 GMT</pubDate>
  <media:content url="https://www.eliasnema.com/posts/newsletter/2020-10-06-ml-history-start.png" medium="image" type="image/png" height="117" width="144"/>
</item>
<item>
  <title>‚öñÔ∏è Democracy and ‚ö° Efficiency</title>
  <dc:creator>Elias Nema</dc:creator>
  <link>https://www.eliasnema.com/posts/newsletter/2020-09-28-newsletter-democracy-efficiency.html</link>
  <description><![CDATA[ 




<section id="democracy-and-efficiency" class="level2">
<h2 class="anchored" data-anchor-id="democracy-and-efficiency">Democracy and Efficiency</h2>
<p>The AI has already proven to work well for many tasks that were not possible to tackle with computers before. Now we‚Äôve entered the scaling phase to make it:</p>
<ul>
<li>as accessible as possible (developer tools, explainability, the <strong>‚Äúdemocratization of ML‚Äù</strong>) and</li>
<li>putting it on as many devices (<strong>model efficiency</strong>) as possible.</li>
</ul>
<p>Hence, more and more ready-to-use recipes are created, frameworks are hiding complexity, and, pre-built models are optimized and ready to be served on all kind of devices.</p>
</section>
<section id="recommendations" class="level2">
<h2 class="anchored" data-anchor-id="recommendations">Recommendations</h2>
<section id="tfrs" class="level3">
<h3 class="anchored" data-anchor-id="tfrs">TFRS</h3>
<p>This one is huge for the RecSys community. Google adds recommendations package into the tensorflow, <em>that makes building, evaluating, and serving sophisticated recommender models easy</em> (this is to the point of democracy).</p>
<p>This also involves <a href="https://twitter.com/maciej_kula?lang=en">Maciej Kula</a>, author of a couple of hugely popular reco libraries: <a href="https://github.com/lyst/lightfm">LightFM</a> and <a href="https://github.com/maciejkula/spotlight">Spotlight</a>. So it promises to be a very elegant API.</p>
<p>And you can see how easy it is to create even a <a href="https://www.tensorflow.org/recommenders/examples/multitask">multitask-system</a>. Here is a code snippet to define two learning tasks, one to predict ratings, another to predict the amount of relevant movies:</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1">tfrs.tasks.Ranking(</span>
<span id="cb1-2">    loss<span class="op" style="color: #5E5E5E;">=</span>tf.keras.losses.MeanSquaredError(),</span>
<span id="cb1-3">    metrics<span class="op" style="color: #5E5E5E;">=</span>[tf.keras.metrics.RootMeanSquaredError()],</span>
<span id="cb1-4">)</span>
<span id="cb1-5"></span>
<span id="cb1-6">tfrs.tasks.Retrieval(</span>
<span id="cb1-7">    metrics<span class="op" style="color: #5E5E5E;">=</span>tfrs.metrics.FactorizedTopK(</span>
<span id="cb1-8">        candidates<span class="op" style="color: #5E5E5E;">=</span>movies.batch(<span class="dv" style="color: #AD0000;">128</span>)</span>
<span id="cb1-9">    )</span>
<span id="cb1-10">)</span></code></pre></div>
<p>Then you can combine these tasks while computing the loss and adjust the weight accordingly. It‚Äôs like Lego for recommendations.</p>
</section>
<section id="linkedins-intents" class="level3">
<h3 class="anchored" data-anchor-id="linkedins-intents">LinkedIn‚Äôs Intents</h3>
<p>A couple of years ago, LinkedIn has joined a cohort of companies that are doing recommendations by intent (members, pages, hashtags, newsletters, etc. in this case) on the main page. Here is a <a href="https://engineering.linkedin.com/blog/2020/helping-members-discover-communities-around-interests">story of how they did it</a>. Some highlights:</p>
<ul>
<li><strong>UI framework:</strong> to be able to quickly switch between recommendation types in the frontend, a unified framework for all the platforms.</li>
<li><strong>[Micro]-Services:</strong> different services for different recommendations with a unified ranker component on top of them. Allows to quickly plug-and-play different algorithms.</li>
<li><strong>Unified tracking:</strong> so often overlooked but such an important mention.</li>
</ul>
</section>
</section>
<section id="efficiency" class="level2">
<h2 class="anchored" data-anchor-id="efficiency">Efficiency</h2>
<section id="nvidia" class="level3">
<h3 class="anchored" data-anchor-id="nvidia">NVIDIA</h3>
<p>Following-up on the <a href="https://www.eliasnema.com/data-meets-product/2020/09/22/newsletter-video.html">last week‚Äôs video topic</a>. Building an ML application on top of a video stream is not something easy and requires expertise in multiple domains. So <a href="https://developer.nvidia.com/blog/deploying-models-from-tensorflow-model-zoo-using-deepstream-and-triton-inference-server/">NVIDIA wants to help</a> you make deployment of such kind of applications easier. This also falls into the <strong>‚Äúdemocratize‚Äù</strong> suit. Here is an excerpt from <a href="https://developer.nvidia.com/blog/implementing-a-real-time-ai-based-face-mask-detector-application-for-covid-19/">their other article</a>, explaining how to build a real-time face-mask detector application:</p>
<blockquote class="blockquote">
<p>To use TLT [NVIDIA‚Äôs transfer learning tool] and DeepStream you do not necessarily have to know all the concepts in depth, such as transfer learning, pruning, quantization, and so on. These simple toolkits abstract away the complexities, allowing you to focus on your application.</p>
</blockquote>
<p>So the modern-day workflow for the AI video app can look like this:</p>
<pre class="text"><code>Download a pretrained model
            |
            |--&gt; Get data for your use case
                        |
                        |--&gt; Retrain (Transfer learning) &amp; Prune
                                    |
                                    |--&gt; Export model and use with DeepStream library</code></pre>
<p>I want to point the <code>Prune</code> part, which is becoming more and more relevant for the production systems. And there are many ways to do it, some I‚Äôve covered in a <a href="https://www.eliasnema.com/data-meets-product/2020/07/20/newsletter-gpt.html">previous post</a>, but you can also check <a href="https://developer.nvidia.com/blog/transfer-learning-toolkit-pruning-intelligent-video-analytics/">NVIDIA‚Äôs blog post</a>.</p>
<p>Why is it important? For example, in the face-mask detection example running on a Jetson Nano after pruning the mean average precision has <strong>dropped from 86.12 to 85.5%</strong>, while frames per second <strong>increased more than 3 times</strong> ‚Äî from 6.5 to 21.25.</p>
<p>This doesn‚Äôt even feel like a trade-off!</p>
<p>Here is also a free course from them to get started with video analytics: <a href="https://courses.nvidia.com/courses/course-v1:DLI+C-IV-02+V1/about">Getting Started with DeepStream for Video Analytics on Jetson Nano</a>.</p>
</section>
<section id="tflites-nlp" class="level3">
<h3 class="anchored" data-anchor-id="tflites-nlp">TFLITE‚Äôs NLP</h3>
<p>And more on the topic of efficiency. Google has <a href="https://blog.tensorflow.org/2020/09/whats-new-in-tensorflow-lite-for-nlp.html">added many things around NLP into the TF Lite</a>.</p>
<p>So that it‚Äôs easier to do things like that in your browser: <img src="https://www.eliasnema.com/posts/newsletter/2020-09-29-bert-browser.png" class="img-fluid" alt="bert-browser"></p>
<p><em>Image from <a href="https://blog.tensorflow.org/2020/03/exploring-helpful-uses-for-bert-in-your-browser-tensorflow-js.html">this blog post</a> about the in-browser BERT.</em></p>
<p>And these capabilities are also unlocked by the pruning and quantization. Just take a look at how much more efficient the model becomes after losing only a fraction in accuracy: <img src="https://www.eliasnema.com/posts/newsletter/2020-09-29-bert-lite.png" class="img-fluid" alt="bert-lite"></p>
</section>
</section>
<section id="pixar" class="level2">
<h2 class="anchored" data-anchor-id="pixar">Pixar</h2>
<p>And after some philosophy let‚Äôs end when it‚Äôs best. If you always wondered how would you look like a Pixar character, now you have a chance <a href="https://toonify.justinpinkney.com/">to see that</a>. As well as an informative <a href="https://www.youtube.com/watch?v=KZ7BnJb30Cc">conversation with its creator</a>.</p>
<blockquote class="twitter-tweet blockquote">
<p lang="en" dir="ltr">
Blending humans and cartoons using <a href="https://twitter.com/Buntworthy?ref_src=twsrc%5Etfw"><span class="citation" data-cites="Buntworthy">@Buntworthy</span></a>'s Google Colab notebook. Thank you for that, it's awesome. Here is a YouTube version of this video: <a href="https://t.co/7bUd7nXaX3">https://t.co/7bUd7nXaX3</a> <a href="https://t.co/iG09lpEAXX">pic.twitter.com/iG09lpEAXX</a>
</p>
‚Äî Doron Adler (<span class="citation" data-cites="Norod78">@Norod78</span>) <a href="https://twitter.com/Norod78/status/1297513475258953728?ref_src=twsrc%5Etfw">August 23, 2020</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>


</section>

 ]]></description>
  <category>newsletter</category>
  <guid>https://www.eliasnema.com/posts/newsletter/2020-09-28-newsletter-democracy-efficiency.html</guid>
  <pubDate>Mon, 28 Sep 2020 23:00:00 GMT</pubDate>
  <media:content url="https://www.eliasnema.com/posts/newsletter/2020-09-29-bert-browser.png" medium="image" type="image/png" height="98" width="144"/>
</item>
<item>
  <title>üìπ Tensorflow.js, AI in Video and Analytics</title>
  <dc:creator>Elias Nema</dc:creator>
  <link>https://www.eliasnema.com/posts/newsletter/2020-09-22-newsletter-video.html</link>
  <description><![CDATA[ 




<section id="ml-in-the-browser" class="level2">
<h2 class="anchored" data-anchor-id="ml-in-the-browser">ML in the Browser</h2>
<p>What can you do with ML in a modern browser? A showcase from the TensorFlow.js community. My personal favorites were:</p>
<ul>
<li><p><a href="https://demos.touch-less.dev/">Touch-less interface for your hand</a>. It takes some time to get used to it and there is still some polishing to be made. However, after a bit of practice, it becomes kind of fun.</p></li>
<li><p><a href="https://enjoyingthe.show/#explainer">Analyze emotions of your audience in real-time</a>, so that your amazing jokes no longer end in awkwardly muted silence.</p></li>
</ul>
<iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/fZ1rzawCPD4?controls=0" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
</iframe>
</section>
<section id="ai-in-video" class="level2">
<h2 class="anchored" data-anchor-id="ai-in-video">AI in Video</h2>
<ul>
<li><p><a href="https://www.synthesia.io/">Synthesia</a> ‚Äî a new service to generate video-content:</p>
<ul>
<li>Chose from predefined narrators</li>
<li>Type the script</li>
<li>It‚Äôll create a video of the person presenting your text in some minutes</li>
</ul></li>
<li><p><a href="https://github.com/tryolabs/norfair">Norfair</a> ‚Äî an open-source library from the <a href="https://tryolabs.com/blog/2020/09/10/releasing-norfair-an-open-source-library-for-object-tracking/">Tyro-labs</a> for the object tracking (cars, pedestrians, poses).</p></li>
<li><p>And if those are not cool enough for you, how about generating realistic tennis matches with real players. <a href="https://cs.stanford.edu/~haotianz/research/vid2player/">Vid2Player</a> does exactly that. Wanted to change the grand-slam history or play Federer against Federer? Well, now you can do that:</p></li>
</ul>
<iframe width="560" height="315" src="https://www.youtube.com/embed/GnZUIuOzgQc" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
</iframe>
<ul>
<li>And since both AI and Video require quite some compute resources and following the horrible launch of 30x cards from NVIDIA, <a href="http://timdettmers.com/2020/09/07/which-gpu-for-deep-learning/">here is a guide</a> on how to chose the one that suits you best while waiting for the cards‚Äô availability.</li>
</ul>
</section>
<section id="analytics" class="level2">
<h2 class="anchored" data-anchor-id="analytics">Analytics</h2>
<p>Relaunch of the analytics blog at Netflix has brought two recent articles. <a href="https://netflixtechblog.com/analytics-at-netflix-who-we-are-and-what-we-do-7d9c08fe6965?source=rss----2615bd06b42e---4">The first one</a> is about the broader role of an analyst. I think this diagram is quite cool and shows the depth of what‚Äôs analytics in data organizations.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://www.eliasnema.com/posts/newsletter/2020-09-22-analytics-netflix.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">analytics-netflix</figcaption><p></p>
</figure>
</div>
<p>In <a href="https://netflixtechblog.com/how-our-paths-brought-us-to-data-and-netflix-4eced44a6872?source=rss----2615bd06b42e---4">the other article from them</a>, there is an interview with a couple of data folks. In the spirit of:</p>
<blockquote class="blockquote">
<p>Everyone wants to build fancy models or tools, but fewer are willing to do the foundational things like cleaning the data and writing the documentation.</p>
</blockquote>
<p>Enough of Netflix. Lastly, an interesting (though quite wordy) <a href="https://counting.substack.com/p/data-cleaning-is-analysis-not-grunt">take on data cleansing</a> and why it‚Äôs not as simple as it‚Äôs often presented. I enjoy a lot the attitude from the author:</p>
<blockquote class="blockquote">
<p>TL;DR: Cleaning data is considered by some people [citation needed] to be menial work that‚Äôs somehow ‚Äúbeneath‚Äù the sexy ‚Äúreal‚Äù data science work. I call BS.</p>
</blockquote>


</section>

 ]]></description>
  <category>newsletter</category>
  <guid>https://www.eliasnema.com/posts/newsletter/2020-09-22-newsletter-video.html</guid>
  <pubDate>Mon, 21 Sep 2020 23:00:00 GMT</pubDate>
  <media:content url="https://www.eliasnema.com/posts/newsletter/2020-09-22-analytics-netflix.png" medium="image" type="image/png" height="132" width="144"/>
</item>
<item>
  <title>üõ¢ Data</title>
  <dc:creator>Elias Nema</dc:creator>
  <link>https://www.eliasnema.com/posts/newsletter/2020-08-03-newsletter-data.html</link>
  <description><![CDATA[ 




<section id="metadata-medical-data-and-tf.data" class="level2">
<h2 class="anchored" data-anchor-id="metadata-medical-data-and-tf.data">Metadata, Medical Data and TF.Data</h2>
<p>Announcements in the metadata management from Shopify and Stripe. What it takes to build a startup in the field of medical AI, and how much time you‚Äôll spend gathering data for it. TensorFlow‚Äôs latest release was mostly about its data API.</p>
</section>
<section id="ai-in-medicine" class="level2">
<h2 class="anchored" data-anchor-id="ai-in-medicine">ü©∫ AI in Medicine</h2>
<p>Highly recommend the <a href="https://www.datafuturology.com/podcast/2020/7/14/127-reinventing-prostate-cancer-testing-with-ai-from-development-to-regulation-to-production-with-elliot-smith-ceo-amp-founder">Data Futurology podcast</a> about what it takes to build an AI company in the medical sphere. Many interesting things, but what it takes to build real-world datasets in the wild is always worth hearing:</p>
<ul>
<li>‚ÄúThere is a lot of differences in medical data ‚Äî if you did MRIs in two different centers, you cannot just take data from both of them and use it.‚Äù</li>
<li>‚ÄúAnother under-appreciated aspect of building a lot of real-world AI applications, where, unlike kaggle, nobody‚Äôs got a 100 thousand in a nicely organized folder‚Ä¶ Sometimes only having data for 10 patients at a time, scans coming on CDs, 1 at a time.‚Äù</li>
</ul>
<blockquote class="blockquote">
<p>‚ÄúAs much as our system involves AI and image processing there is probably just as much if not more work in around data standardization, data cleanliness and manual intervention into data.‚Äù</p>
</blockquote>
<ul>
<li>2.5 years (from 5!) were spent on building a political relationship (with doctors), gathering data piece by piece, later building integrations with existing systems.</li>
<li>‚ÄúThe best results were coming from building a relationship with individual doctors.‚Äù</li>
</ul>
<p>To sum it up, I think that data gathering relationship building is <strong>the new sales</strong>. Building a company that relies on data, you are as good as the number of data providers you‚Äôve built a relationship with.</p>
</section>
<section id="metadata" class="level2">
<h2 class="anchored" data-anchor-id="metadata">üìº Metadata</h2>
<p>Two of the big players have released something about their metadata solutions. Many of the big players already have established solutions for a couple of years, with Shopify being the latest company to build their own.</p>
<section id="shopifys-artifact" class="level3">
<h3 class="anchored" data-anchor-id="shopifys-artifact"><a href="https://engineering.shopify.com/blogs/engineering/solving-data-discovery-challenges-shopify">Shopify‚Äôs Artifact</a></h3>
<ul>
<li>Their implementation uses Elasticseach and a graph database to provide search and data lineage respectively. GraphQL‚Äôs Apollo as an API layer. Quite a standard stack. Similar to e.g.&nbsp;<a href="https://lyft.github.io/amundsen/architecture/">this one</a>.</li>
<li>Other than that, from the screenshots it looks like it does what it should and looks very much like similar systems. However, a quote from the article explaining why it‚Äôs generally hard to reuse existing solutions:</li>
</ul>
<blockquote class="blockquote">
<p>Every organization‚Äôs data stack is different. While some upstream processes can be standardized and cataloged appropriately, the business context of downstream processes creates a wide distribution of requirements that are near impossible to satisfy with a one-size-fits-all solution.</p>
</blockquote>
</section>
<section id="stripe-and-privacy" class="level3">
<h3 class="anchored" data-anchor-id="stripe-and-privacy">Stripe and Privacy</h3>
<p><a href="https://developer.squareup.com/blog/using-amundsen-to-support-user-privacy-via-metadata-collection-at-square/">Stripe is using</a> their <a href="https://lyft.github.io/amundsen/">Amundsen</a> metadata tool to increase focus on consumer privacy and better comply with GDPR and CCPA.</p>
</section>
<section id="other-companies" class="level3">
<h3 class="anchored" data-anchor-id="other-companies">Other companies</h3>
<p>A collection of <a href="https://github.com/eugeneyan/applied-ml">data discovery articles</a>.</p>
</section>
</section>
<section id="tensorflow-2.3" class="level2">
<h2 class="anchored" data-anchor-id="tensorflow-2.3">üñá Tensorflow 2.3</h2>
<p>Ironically the <a href="https://blog.tensorflow.org/2020/07/whats-new-in-tensorflow-2-3.html">latest TensorFlow release</a> is also about data. Two of the main additions to the help make preprocessing smoother. I think preprocessing may very well be the most overlooked step and improving it is hugely beneficial.</p>
<ul>
<li><strong>td.data.snapshot</strong>: allows you to run the preprocessing pipeline once, save the output and play with parameter optimization on top of that. Read more details in the <a href="https://github.com/tensorflow/community/blob/master/rfcs/20200107-tf-data-snapshot.md">RFC</a>.</li>
<li><strong><a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing?version=nightly">Preprocessing layer API</a></strong>: package preprocessing logic inside a model for easier deployment.</li>
</ul>
<hr>
<p><br></p>
<p>To finish on a positive note, here is an awesome 3 minutes <a href="https://www.youtube.com/watch?v=kpiY_LemaTc">Lex Fridman‚Äôs video</a> estimating costs for GPT to equal a human brain:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://www.eliasnema.com/posts/newsletter/2020-08-03.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">gpt costs</figcaption><p></p>
</figure>
</div>


</section>

 ]]></description>
  <category>newsletter</category>
  <guid>https://www.eliasnema.com/posts/newsletter/2020-08-03-newsletter-data.html</guid>
  <pubDate>Sun, 02 Aug 2020 23:00:00 GMT</pubDate>
  <media:content url="https://www.eliasnema.com/posts/newsletter/2020-08-03.png" medium="image" type="image/png" height="70" width="144"/>
</item>
<item>
  <title>üîé Paid Search</title>
  <dc:creator>Elias Nema</dc:creator>
  <link>https://www.eliasnema.com/posts/newsletter/2020-07-28-newsletter-search.html</link>
  <description><![CDATA[ 




<p>This week I ended up reading a couple of recent articles around the topic of search. Not groundbreaking paper‚Äôs style. Rather down-to-earth field implementations. Below, I‚Äôll go through the paid search challenges in two major online platforms. And then to the emerging role of a Relevance Engineer.</p>
<section id="pinterest" class="level2">
<h2 class="anchored" data-anchor-id="pinterest"><img src="https://www.eliasnema.com/posts/newsletter/pinterest.png" width="35"> Pinterest</h2>
<p><a href="https://medium.com/pinterest-engineering/driving-shopping-upsells-from-pinterest-search-d06329255402">Shopping upsells on Pinterest</a>. An interesting story. Let me decompose it to the common steps seen across data projects.</p>
<p>A simple problem to solve ‚Äî introduce ads into the search results. They call it ‚Äúshopping upsells‚Äú. Imagine you need to build a shopping upsell model.</p>
<section id="step-1.-get-data." class="level3">
<h3 class="anchored" data-anchor-id="step-1.-get-data.">Step 1. Get Data.</h3>
<p>Where to get the data for a feature that doesn‚Äôt yet exist on a platform?</p>
<ul>
<li>One approach: randomly display a portion of upsells for all queries. However, this way the product quality is mixed with the user intent for shopping ‚Äî not clear if the user doesn‚Äôt want to buy in general or doesn‚Äôt like this particular ad.</li>
<li>A better approach: <em>embed products in both upsell and organic sections</em>, but hide prices in organic. This way is possible to distill the intent of a user and make data less noisy.</li>
</ul>
</section>
<section id="step-2.-get-model." class="level3">
<h3 class="anchored" data-anchor-id="step-2.-get-model.">Step 2. Get Model.</h3>
<p>You‚Äôve got data, get a model.</p>
<ul>
<li>Use business knowledge to come up with a smart objective. Clicks on products are usually noisy, but a good first start. Much better to assign proper weights to strong signals and smartly combine them. Pinterest uses pins and clicks to partner sites.</li>
<li><a href="https://miro.medium.com/max/300/0*kI9UvZRbnPFM1RJ2">Model architecture</a>:<br>
<code>Query -&gt; Embedding -&gt; Encoder -&gt; Dense -&gt; Log Loss</code></li>
</ul>
<p>New practitioners are often disappointed by seeing simple architectures after all the resnets and RNNs they‚Äôve just studied. But complexity and state-of-the-arts are often wrong fallacies to chase for most of the businesses.</p>
</section>
<section id="step-3a.-get-results." class="level3">
<h3 class="anchored" data-anchor-id="step-3a.-get-results.">Step 3a. Get Results.</h3>
<blockquote class="blockquote">
<p>‚ÄúAfter launching the experiment, the model increased more than 2X traffic to the shopping search page without hurting overall search metrics in terms of long clicks or saves. The model also increased more than 2X product impressions and product long clicks through the upsell.‚Äú</p>
</blockquote>
</section>
<section id="step-3b.-hack-production." class="level3">
<h3 class="anchored" data-anchor-id="step-3b.-hack-production.">Step 3b. Hack Production.</h3>
<p>Having the results you now need to hack the costs to get the ‚Äúmodel economics‚Äù right.</p>
<ul>
<li>For example, they are smartly precomputing head queries and filtering out ‚Äúnon-shoppable categories, such as ‚Äòrecipe‚Äô or ‚Äòfinance‚Äô.‚Äù</li>
</ul>
<p>My bet is that Pinterest didn‚Äôt come up with these optimizations from the beginning. Usually, it‚Äôs a loop of 2-3b steps until you get all the components right. This often-overlooked cycle of small adjustments, in this case, allowed to reduce model serving traffic by 70% ü§Ø</p>
</section>
</section>
<section id="ebay" class="level2">
<h2 class="anchored" data-anchor-id="ebay"><img src="https://www.eliasnema.com/posts/newsletter/ebay.png" width="35"> Ebay</h2>
<p><a href="https://tech.ebayinc.com/product/ebay-makes-promoted-listings-in-search-results-more-relevant-and-dynamic/">Ebay‚Äôs article</a> on balancing paid and non-paid content in their search results.</p>
<p>The basic idea is that having fixed paid slots is bad. Both for the:</p>
<ul>
<li><em>head queries</em>, for which there is much more paid content than it‚Äôs possible to fit</li>
<li>as well as <em>tail queries</em>, for which there is often not enough high-quality paid content</li>
</ul>
<p>The solution? Get rid of the fixed paid slots and rank the whole search result according to ‚Äúrelevancy‚Äú. Here is a more detailed summary:</p>
<blockquote class="twitter-tweet blockquote">
<p lang="en" dir="ltr">
<a href="https://twitter.com/ebaytech?ref_src=twsrc%5Etfw"><span class="citation" data-cites="ebaytech">@ebaytech</span></a> has recently released an article on balancing the paid and non-paid content in their search result page (thread)‚Å∞<a href="https://twitter.com/hashtag/ecommerce?src=hash&amp;ref_src=twsrc%5Etfw">#ecommerce</a> <a href="https://twitter.com/hashtag/Search?src=hash&amp;ref_src=twsrc%5Etfw">#Search</a> <a href="https://twitter.com/hashtag/marketplace?src=hash&amp;ref_src=twsrc%5Etfw">#marketplace</a> ‚Å∞<a href="https://t.co/REualIf6Aq">https://t.co/REualIf6Aq</a>
</p>
‚Äî Elias Nema (<span class="citation" data-cites="EliasNema">@EliasNema</span>) <a href="https://twitter.com/EliasNema/status/1286420652539424773?ref_src=twsrc%5Etfw">July 23, 2020</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</section>
<section id="ds-or-ml-re" class="level2">
<h2 class="anchored" data-anchor-id="ds-or-ml-re">üïµÔ∏è‚Äç‚ôÄÔ∏è DS or ML? RE!</h2>
<p><a href="https://opensourceconnections.com/blog/2020/07/16/what-is-a-relevance-engineer/">Another interesting take</a> on the career in the data field from one of the most famous search practitioners. A couple of highlights:</p>
<ul>
<li>Who is a relevance engineer: <em>‚Äúimplements information retrieval algorithms that solve user information needs in real time, at scale‚Äú</em></li>
<li>Applied approach: <em>‚Äúdon‚Äôt chase the state of the art unnecessarily, rather they prefer proven techniques for 80% of the problem‚Äú, ‚Äúdon‚Äôt solve search for Kaggle points or academia, but for real companies and users‚Äú</em></li>
<li>How it‚Äôs different from ML engineer: both roles are very similar, with relevance engs tending to be more user-centric and focused on IR problems (ML is broader and not necessarily user-facing problems)</li>
</ul>
<p>I think the role will become more popular going forward with many companies realizing the need and value of showing relevant content to users in an ever-shrinking customer attention span.</p>


</section>

 ]]></description>
  <category>newsletter</category>
  <guid>https://www.eliasnema.com/posts/newsletter/2020-07-28-newsletter-search.html</guid>
  <pubDate>Mon, 27 Jul 2020 23:00:00 GMT</pubDate>
  <media:content url="https://www.eliasnema.com/posts/newsletter/ebay.png" medium="image" type="image/png" height="97" width="144"/>
</item>
<item>
  <title>üí• GPT Excitement and AI Costs</title>
  <dc:creator>Elias Nema</dc:creator>
  <link>https://www.eliasnema.com/posts/newsletter/2020-07-20-newsletter-gpt.html</link>
  <description><![CDATA[ 




<section id="a-week-of-gpt-3-obviously" class="level2">
<h2 class="anchored" data-anchor-id="a-week-of-gpt-3-obviously">A Week of GPT-3, Obviously</h2>
<p>There were so many tweets, articles and general excitement that it became too much even for Sam Altman himself:</p>
<blockquote class="twitter-tweet blockquote">
<p lang="en" dir="ltr">
The GPT-3 hype is way too much. It‚Äôs impressive (thanks for the nice compliments!) but it still has serious weaknesses and sometimes makes very silly mistakes. AI is going to change the world, but GPT-3 is just a very early glimpse. We have a lot still to figure out.
</p>
‚Äî Sam Altman (<span class="citation" data-cites="sama">@sama</span>) <a href="https://twitter.com/sama/status/1284922296348454913?ref_src=twsrc%5Etfw">July 19, 2020</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
<p>I‚Äôm, of course, impressed too. In fact, it was able to produce my most liked tweet üòû (and same happened to some better-known folks):</p>
<blockquote class="twitter-tweet blockquote" data-conversation="none">
<p lang="en" dir="ltr">
Side note: if this somehow becomes my most viewed tweet ever, I'm going to be sad.
</p>
‚Äî Leo Polovets (<span class="citation" data-cites="lpolovets">@lpolovets</span>) <a href="https://twitter.com/lpolovets/status/1284288703200817153?ref_src=twsrc%5Etfw">July 18, 2020</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
<p>There are many great articles covering GPT-3 and its meaning for the future of humanity. You can easily find them, but probably don‚Äôt need to, because they pop up everywhere.</p>
<p>Hype aside, it‚Äôs a huge model and probably costs a fortune, but the whole product part is done in a very lean way. It‚Äôs at the market validation phase, which it has nailed perfectly.</p>
<blockquote class="twitter-tweet blockquote">
<p lang="en" dir="ltr">
In the ultimate lean startup twist it turned out that <a href="https://twitter.com/sama?ref_src=twsrc%5Etfw"><span class="citation" data-cites="sama">@sama</span></a> was manually answering all GPT-3 requests.
</p>
‚Äî Andreas Klinger ‚úåÔ∏è (<span class="citation" data-cites="andreasklinger">@andreasklinger</span>) <a href="https://twitter.com/andreasklinger/status/1283981585251880961?ref_src=twsrc%5Etfw">July 17, 2020</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
<p>Probably, the next step would be to optimize costs and <strong>make the economics right</strong> for the rest of the internet. Which brings us to the topic of costs, which becomes as relevant as never for the AI/ML community.</p>
</section>
<section id="costs-in-ai" class="level2">
<h2 class="anchored" data-anchor-id="costs-in-ai">üí∞Costs in AI</h2>
<ul>
<li>A very interesting conversation on last <a href="https://twimlai.com/twiml-talk-391-the-case-for-hardware-ml-model-co-designwith-diana-marculescu/">week‚Äôs TWIML AI podcast</a> about model design optimization for hardware.</li>
<li><a href="https://www.wired.com/story/prepare-artificial-intelligence-produce-less-wizardry/">Another article</a> suggests that despite shaving off 3/4 of errors in logistic optimization prediction with the help of deep learning, a European retailer chose not to use the model because of costs.</li>
</ul>
<p>Until very recently, DL has been driven by the research in big companies. This means almost unlimited resources. It‚Äôs great to validate and/or win the market. But with time, you need to get the unit economics right. For training and serving and smaller devices (a smartphone in 2017 was able to run <a href="https://arxiv.org/pdf/1611.05128.pdf">AlexNet only for 1 hour</a>).</p>
<p>Basically there are multiple directions in ML optimizations:</p>
<ul>
<li>Incorporating <a href="https://workshop-edlcv.github.io/slides/901-talk.pdf">power/energy/latency constraints</a> into network architectures search. This <em>‚Äúcan bring 5‚Äê10x improvement in energy or latency with minimal loss in accuracy or can satisfy real-time constraints for inference‚Äù</em>. Basically, by thinking about hardware constraints in advance you can get to almost the same accuracy while saving in the order of magnitudes. An amazing trade-off for most of the businesses.</li>
<li><a href="https://arxiv.org/pdf/1904.02835.pdf">Quantizing neural networks</a>. The idea here is to round model weights to the nearest power of 2, hence allowing using shift and add operations to replace the multiplications. This improves speed and lowers energy consumption. A very smart approach and again, a well-worse trade-off.</li>
<li><a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Chin_Towards_Efficient_Model_Compression_via_Learned_Global_Ranking_CVPR_2020_paper.pdf">Energy-aware pruning of NNs</a>: Often both accuracy and latency are important to the application. This work allows you to quickly iterate over accuracy-vs.-speed trade-off for finding a sweet-spot for a particular application using model compression.</li>
<li><a href="https://arxiv.org/pdf/1806.03198.pdf">Discretizing vectors over a d-dimensional sphere</a>: A super-smart approach where instead of adapting an index to the data, the data is adopted to the index itself. <em>‚ÄúWe learn a neural network that aims at preserving the neighborhood structure in the input space while best covering the output space (uniformly)‚Äù</em>.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://www.eliasnema.com/posts/newsletter/to_uniform.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">to uniform</figcaption><p></p>
</figure>
</div>
<p>These are just the directions I‚Äôve seen recently. But the topic is becoming more and more important. If AI aims to turn into a new cloud, the industry needs to figure out the ways to scale the ‚Äústate-of-the-art‚Äú to the rest of the internet. And it looks like we are finally getting there.</p>


</section>

 ]]></description>
  <category>newsletter</category>
  <guid>https://www.eliasnema.com/posts/newsletter/2020-07-20-newsletter-gpt.html</guid>
  <pubDate>Sun, 19 Jul 2020 23:00:00 GMT</pubDate>
  <media:content url="https://www.eliasnema.com/posts/newsletter/to_uniform.png" medium="image" type="image/png" height="33" width="144"/>
</item>
<item>
  <title>üìµ No Code and ML Interns</title>
  <dc:creator>Elias Nema</dc:creator>
  <link>https://www.eliasnema.com/posts/newsletter/2020-07-13-newsletter-no-code.html</link>
  <description><![CDATA[ 




<p>Is no code the new oil or the old ETL? TikTok‚Äôs recommender and when to use machine learning.</p>
<section id="no-code" class="level2">
<h2 class="anchored" data-anchor-id="no-code">üìµ No Code</h2>
<ul>
<li>When AWS launches a service, there is usually good economics behind it. Recently they‚Äôve launched the <a href="https://www.honeycode.aws/">no-code way to build simple mobile apps</a>. It continues the trend started by Notion, Airtable and the likes of building your own productivity tools (of course, AWS is not competing against the Notion but rather against Microsoft Power Apps here). Spreadsheets for the new era.</li>
<li>The Russian design studio <a href="https://www.artlebedev.com/ironov/">was using AI</a> as one of their designers for more than a year. &gt; ‚ÄùThis event marks the moment that the mass automation of creative processes becomes a reality for businesses.‚Äù</li>
<li><a href="https://techcrunch.com/2020/07/07/monkeylearn-raises-2-2m-to-build-out-its-no-code-ai-text-analysis-service/">MonkeyLearn raises 2.2M$</a> - not really no-code AI, rather NLP as a service. &gt; ‚ÄúOur vision is to make AI approachable by providing a toolkit for teams to actually use AI in their daily operations,‚Äù Garreta said in a release.</li>
<li>Adobe keeps investing in its Sensei AI platform adding seamless no code <a href="https://www.adobe.com/marketing/target.html#demo">personalization and recommenders</a> based on AL and ML, of course. Allows you to automatically A/B test different content variants and more.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://www.eliasnema.com/posts/newsletter/adobe_sensei.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Automatically Testing Multiple Onboarding Flows with Adobe Sensei</figcaption><p></p>
</figure>
</div>
</section>
<section id="ml-applications" class="level2">
<h2 class="anchored" data-anchor-id="ml-applications">üéõ ML Applications</h2>
<ul>
<li>Facebook will <a href="https://about.fb.com/news/2020/06/prioritizing-original-news-reporting-on-facebook/">prioritize original reporting</a> in the home feed. To identify originals it will look at how often the article is cited as ‚Ä¶ original.</li>
<li><a href="https://www.producthunt.com/posts/virtual-models-by-rosebud-ai">A nice launch on ProductHunt</a> using GANs to generate models (real ones) for ‚Äúphotoshoots‚Äú. Even though the demo is far from perfect. But with the recent e-commerce rise, covid restrictions and all the shopify storefronts, this might be a promising direction. If the model (ML model, in this case) economy can be figured out.</li>
<li>TikTok‚Äôs recommenders are apparently really good:</li>
</ul>
<blockquote class="twitter-tweet blockquote">
<p lang="en" dir="ltr">
According to my teenagers, Tiktok has by far the best personalized <a href="https://twitter.com/hashtag/RecSys?src=hash&amp;ref_src=twsrc%5Etfw">#RecSys</a> they have used. Do we know anything about what they are doing?
</p>
‚Äî Xavier Amatriain - üåàüí™üèø (<span class="citation" data-cites="xamat">@xamat</span>) <a href="https://twitter.com/xamat/status/1282467657535467520?ref_src=twsrc%5Etfw">July 13, 2020</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
<p>And my thread about their recent article about how their recommender works:</p>
<blockquote class="twitter-tweet blockquote">
<p lang="en" dir="ltr">
<a href="https://twitter.com/hashtag/Tiktok?src=hash&amp;ref_src=twsrc%5Etfw">#Tiktok</a> has posted an article about their <a href="https://twitter.com/hashtag/recommendations?src=hash&amp;ref_src=twsrc%5Etfw">#recommendations</a> system. There aren't too many details, but some interesting quotes on how they think about the problem space.<br>(1/)<a href="https://t.co/Ou8LfBGjUe">https://t.co/Ou8LfBGjUe</a>
</p>
‚Äî Elias Nema (<span class="citation" data-cites="EliasNema">@EliasNema</span>) <a href="https://twitter.com/EliasNema/status/1278803346321801217?ref_src=twsrc%5Etfw">July 2, 2020</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</section>
<section id="why-ml-is-similar-to-interns" class="level2">
<h2 class="anchored" data-anchor-id="why-ml-is-similar-to-interns">üëî Why ML is Similar to Interns</h2>
<p>Finishing with an interesting tweet from Benedict Evans:</p>
<blockquote class="twitter-tweet blockquote">
<p lang="en" dir="ltr">
I quite often describe machine learning as giving you infinite interns. This can be a useful way to look at how ML would affect a product: sometimes having infinite free interns to look at data for you wouldn‚Äôt actually solve your problems, and the struggle is something else.
</p>
‚Äî Benedict Evans (<span class="citation" data-cites="benedictevans">@benedictevans</span>) <a href="https://twitter.com/benedictevans/status/1280265572782145537?ref_src=twsrc%5Etfw">July 6, 2020</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
<p>I think this is a very good summary for execs who don‚Äôt have exposure to the topic. Or for product managers when thinking about prioritization. Very often people tend to forget that ML is about <strong>automation</strong>. Imagine, you have an amazing photo-artist, who can look at the photos you take, pick the best ones, adjust brightness here and there, suggest collages, design a photo book and send to you. This is an awesome service, but also a very expensive one. How about providing it to a billion people? Hence, <strong>Google Photos</strong> cannot compete with the quality of the artist but can provide the service to a billion customers. Same goes for recommendations: a good stylist can probably get you a fashionable outfit, but economics cannot beat the recsys approach (or it can if you are a boutique).</p>
<p>On the other hand, problems where many agents won‚Äôt help, such as: shall we launch in the new market, how will customers react to a new feature? These are non-scalable problems. And even if you can and should use data to make a conscious decision there, investing in the ML solution won‚Äôt bring benefits.</p>
<p>Too often people confuse the need of <strong>scaling the decision</strong> (good for ML interns) with the need of <strong>taking a good decision from time to time</strong> (ML is of no use here).</p>


</section>

 ]]></description>
  <category>newsletter</category>
  <guid>https://www.eliasnema.com/posts/newsletter/2020-07-13-newsletter-no-code.html</guid>
  <pubDate>Sun, 12 Jul 2020 23:00:00 GMT</pubDate>
  <media:content url="https://www.eliasnema.com/posts/newsletter/adobe_sensei.png" medium="image" type="image/png" height="85" width="144"/>
</item>
</channel>
</rss>
