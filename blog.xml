<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>ELIAS NEMA</title>
<link>https://www.eliasnema.com/blog.html</link>
<atom:link href="https://www.eliasnema.com/blog.xml" rel="self" type="application/rss+xml"/>
<description>Making data work: analytics, personalisation, relevance and recommender systems - whatever is takes.</description>
<generator>quarto-1.7.32</generator>
<lastBuildDate>Fri, 17 Mar 2023 00:00:00 GMT</lastBuildDate>
<item>
  <title>Data Feed #6: JSON {}</title>
  <dc:creator>Elias Nema</dc:creator>
  <link>https://www.eliasnema.com/posts/newsletter/2023-03-17.html</link>
  <description><![CDATA[ 





<section id="focus-json" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="focus-json">Focus: JSON</h2>
<p>PostgreSQL can deal with JSON for a very long time (and here is a great history<sup>1</sup> of it), but now is also able to write the server log in JSON format.<sup>2</sup></p>
<div class="no-row-height column-margin column-container"><div id="fn1"><p><sup>1</sup>&nbsp;<a href="https://www.infoworld.com/article/3651356/jsonb-in-postgresql-today-and-tomorrow.html">JSONB in PostgreSQL today and tomorrow</a></p></div><div id="fn2"><p><sup>2</sup>&nbsp;<a href="https://www.cybertec-postgresql.com/en/json-logs-in-postgresql-15/">JSON logs in PostgreSQL 15</a></p></div><div id="fn3"><p><sup>3</sup>&nbsp;<a href="https://www.cockroachlabs.com/blog/high-performance-json-parsing/">High-performance JSON parsing in Go</a></p></div></div><p>A deep dive into the potential performance issues when parsing JSON.<sup>3</sup></p>
<p><a href="https://planetscale.com/blog/the-mysql-json-data-type">The MySQL JSON data type.</a></p>
<p>In SQLite, JSON functions are built-in and on by default since 3.38, along with <code>-&gt;</code> and <code>-&gt;&gt;</code> operators, compatible with MySQL and PostgreSQL.<sup>4</sup></p>
<div class="no-row-height column-margin column-container"><div id="fn4"><p><sup>4</sup>&nbsp;<a href="https://www.sqlite.org/releaselog/3_38_0.html">SQLite Release 3.38.0</a></p></div></div><p>DuckDB:</p>
<ul>
<li>DuckDB can read JSON files as tables, and here is an example of querying GH Archive data.<sup>5</sup></li>
<li>JSON support was a big part of a DuckDB 0.7.0 release.<sup>6</sup></li>
</ul>
<div class="no-row-height column-margin column-container"><div id="fn5"><p><sup>5</sup>&nbsp;<a href="https://duckdb.org/2023/03/03/json.html">Shredding Deeply Nested JSON, One Vector at a Time</a></p></div><div id="fn6"><p><sup>6</sup>&nbsp;<a href="https://duckdb.org/2023/02/13/announcing-duckdb-070.html">Announcing DuckDB 0.7.0</a></p></div></div></section>
<section id="learning" class="level2">
<h2 class="anchored" data-anchor-id="learning">Learning</h2>
<p><a href="https://www.cockroachlabs.com/blog/what-is-a-uuid/">What is a UUID, and what is it used for?</a></p>
<p>Data migrations are still of the hardest problems in engineering, and AWS has written a couple of recent articles about that:</p>
<ul>
<li><a href="https://aws.amazon.com/blogs/database/migrate-an-internet-scale-online-transactional-system-to-amazon-dynamodb-using-aws-dms/">Migrate an internet-scale online transactional system to Amazon DynamoDB using AWS DMS.</a></li>
<li><a href="https://aws.amazon.com/blogs/database/how-skai-performed-database-and-migration-with-aws-dms/">How Skai performed database modernization and migration with AWS DMS.</a></li>
</ul>
<p><a href="https://www.crunchydata.com/blog/easy-postgresql-time-bins">Easy PostgreSQL time bins.</a></p>
<p><a href="https://techcommunity.microsoft.com/t5/azure-database-for-postgresql/announcing-data-api-builder-preview-for-postgresql/ba-p/3766768">Announcing Data API Builder (preview) for PostgreSQL.</a></p>
<p><a href="https://redpanda.com/blog/advertised-kafka-address-explanation">What is advertised Kafka address?</a></p>
<p><a href="https://passdatacommunitysummit.com/">PASS Data Community Summit</a> is in Seattle on November 14-17 with a call for speakers still open.</p>
<p><a href="https://redpanda.com/blog/stream-processing-apache-flink-etl">Getting started: Stream processing using Apache Flink and Redpanda.</a></p>
</section>
<section id="deep-dive" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="deep-dive">Deep Dive</h2>
<p>An AMAZING, more than 600 pages book focusing on PostgreSQL internals.<a href="https://www.eliasnema.com/data-feed/2023-03-17.html#fn7"><sup>7</sup></a> A must-read!</p>
<p>Enabling <a href="https://docs.oracle.com/database/121/UNXAR/appi_vlm.htm#UNXAR391">Linux Huge Pages</a> for Postgres and MySQL.<sup>7</sup></p>
<div class="no-row-height column-margin column-container"><div id="fn7"><p><sup>7</sup>&nbsp;<a href="http://smalldatum.blogspot.com/2023/03/huge-pages-with-postgres-innodb-better.html">Huge pages with Postgres &amp; InnoDB: better perf, but a bit more work.</a></p></div></div><p><a href="https://www.enterprisedb.com/blog/performance-comparison-major-PostgreSQL-versions">Performance comparison of the major PostgreSQL versions.</a></p>
<p>Overview of machine learning-based automatic database tuning techniques at OtterTune.<sup>8</sup></p>
<div class="no-row-height column-margin column-container"><div id="fn8"><p><sup>8</sup>&nbsp;<a href="https://ottertune.com/blog/ottertune-1-5-to-2-0-where-we-are-and-where-were-going/">OtterTune 1.5 to 2.0: Where We Are and Where We’re Going</a></p></div></div><p><a href="https://www.cybertec-postgresql.com/en/bad-check-constraints-postgresql/">Breaking your PostgreSQL database with bad <code>CHECK</code> constraints.</a></p>
</section>
<section id="business" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="business">Business</h2>
<p><a href="https://cloud.google.com/blog/products/ai-machine-learning/top-5-data-and-ai-trends-this-year">The top five global data and AI trends in 2023 from Google Cloud.</a></p>
<p>A new whitepaper from AWS on Data Lakes cost modeling best practices.<sup>9</sup></p>
<div class="no-row-height column-margin column-container"><div id="fn9"><p><sup>9</sup>&nbsp;<a href="https://docs.aws.amazon.com/whitepapers/latest/cost-modeling-data-lakes/defining-the-approach-to-cost-modeling-data-lakes.html">Cost modeling Data Lakes for beginners</a></p></div></div><p><a href="https://www.enterprisedb.com/blog/Postgres-Powered-Community-Open-Source">Community and open source: the secret to PostgreSQL’s success.</a></p>
<p><a href="https://www.yugabyte.com/blog/database-security-stability-client-satisfaction-fiserv/">Prioritizing security, stability, and client satisfaction: insight from Fiserv’s VP and fellow architect.</a></p>


</section>


 ]]></description>
  <guid>https://www.eliasnema.com/posts/newsletter/2023-03-17.html</guid>
  <pubDate>Fri, 17 Mar 2023 00:00:00 GMT</pubDate>
  <media:content url="https://www.eliasnema.com/posts/df2-small.png" medium="image" type="image/png"/>
</item>
<item>
  <title>Data Feed #5: GEO</title>
  <dc:creator>Elias Nema</dc:creator>
  <link>https://www.eliasnema.com/posts/newsletter/2023-03-10.html</link>
  <description><![CDATA[ 





<p>You should also check out a recent <a href="https://www.eliasnema.com/data-feed/paper-transactional-model/paper-transactional.html">deep dive into a foundational paper</a> - “The Transaction Concept: Virtues and Limitations” by Jim Gray, 1981.</p>
<section id="focus-geo" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="focus-geo">Focus: GEO</h2>
<p>A couple of great posts from <a href="https://tech.marksblogg.com/">Mark Litwintschik</a>:</p>
<ul>
<li>Exploration of a FlixBus dataset and using SQL for some route planning.<sup>1</sup></li>
<li>DuckDB for geospatial data (spoiler: it outperformed previous winner ClickHouse).<sup>2</sup></li>
</ul>
<div class="no-row-height column-margin column-container"><div id="fn1"><p><sup>1</sup>&nbsp;<a href="https://tech.marksblogg.com/route-planning-europe-postgresql-pgrouting.html">European Route Planning</a></p></div><div id="fn2"><p><sup>2</sup>&nbsp;<a href="https://tech.marksblogg.com/duckdb-geospatial-gis.html">Geospatial DuckDB</a></p></div></div><p>H3 extensions:</p>
<ul>
<li><a href="https://github.com/isaacbrodsky/h3-duckdb">h3-duckdb</a></li>
<li><a href="https://blog.rustprooflabs.com/2022/06/h3-indexes-on-postgis-data">H3 indexes for performance with PostGIS data.</a></li>
</ul>
<p>Another approach is to use a web API-based geocoder. Here is an example from a Crunchy Bridge.<sup>3</sup></p>
<div class="no-row-height column-margin column-container"><div id="fn3"><p><sup>3</sup>&nbsp;<a href="https://www.kschaul.com/post/2023/02/16/how-the-post-is-replacing-mapbox-with-open-source-solutions/">How The Post is replacing Mapbox with open source solutions</a></p></div><div id="fn4"><p><sup>4</sup>&nbsp;<a href="https://supabase.com/blog/geo-queries-with-postgis-in-ionic-angular">Geo Queries with PostGIS in Ionic Angular</a></p></div></div><p>Using PostGIS in Supabase to build an app in Ionic Angular.<sup>4</sup></p>
</section>
<section id="vectors" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="vectors">Vectors</h2>
<p>Following up on <a href="https://www.eliasnema.com/data-feed/2023-03-03.html">last week’s issue about vectors</a>, here is an amazing SQLite extension for vector search, that is based on faiss.<sup>5</sup></p>
<div class="no-row-height column-margin column-container"><div id="fn5"><p><sup>5</sup>&nbsp;<a href="https://observablehq.com/@asg017/introducing-sqlite-vss">Introducing sqlite-vss</a></p></div></div></section>
<section id="learning" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="learning">Learning</h2>
<p><a href="https://aws.amazon.com/blogs/big-data/simplify-data-loading-into-type-2-slowly-changing-dimensions-in-amazon-redshift/">Simplify data loading into Type 2 slowly changing dimensions in Amazon Redshift.</a></p>
<p><a href="https://www.philipotoole.com/9-years-of-open-source-database-development-the-design-docs/">9 years of open-source database development: reviewing rqlite design choices.</a></p>
<p><a href="https://www.timescale.com/blog/best-practices-for-time-series-data-modeling-single-or-multiple-partitioned-table-s-a-k-a-hypertables/">Best practices for time-series data modeling: single or multiple partitioned table(s) a.k.a. hypertables.</a></p>
<p><a href="https://aws.amazon.com/blogs/database/choose-the-right-postgresql-data-access-pattern-for-your-saas-application/">Choose the right PostgreSQL data access pattern for your SaaS application.</a></p>
<p><a href="https://redpanda.com/blog/placement-groups-high-availability-cluster">How to use Placement Groups to achieve high availability.</a></p>
<p><a href="https://www.scylladb.com/2023/03/08/rust-in-the-real-world-super-fast-data-ingestion-using-scylladb/">Rust in the real world: super fast data ingestion using ScyllaDB.</a></p>
<p><a href="https://aws.amazon.com/blogs/big-data/build-an-end-to-end-change-data-capture-with-amazon-msk-connect-and-aws-glue-schema-registry/">Build an end-to-end change data capture with Amazon MSK Connect and AWS Glue Schema Registry.</a></p>
<p><a href="https://www.yugabyte.com/blog/design-indexes-query-performance-distributed-database/">How to design distributed indexes for optimal query performance.</a></p>
<p>Amazon Athena editor is finally getting quite a few keyboard shortcuts🙌 <sup>6</sup></p>
<div class="no-row-height column-margin column-container"><div id="fn6"><p><sup>6</sup>&nbsp;<a href="https://aws.amazon.com/blogs/big-data/improve-productivity-by-using-keyboard-shortcuts-in-amazon-athena-query-editor/">Improve productivity by using keyboard shortcuts in Amazon Athena query editor</a></p></div></div></section>
<section id="upcoming-conferences" class="level2">
<h2 class="anchored" data-anchor-id="upcoming-conferences">Upcoming Conferences</h2>
<p>Distributed <a href="https://www.yugabyte.com/blog/distributed-sql-summit-asia-registration-is-now-open/">SQL Summit</a> by YugabyteDB.</p>
<p>Cassandra Forward and <a href="https://www.datastax.com/blog/cassandraforward">why you don’t want to miss it</a>.</p>
</section>
<section id="deep-dive" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="deep-dive">Deep Dive</h2>
<p>Great stories with examples from Quora on challenges faced in modelling, querying and writing to a DB of an internet-scale service.<sup>7</sup></p>
<div class="no-row-height column-margin column-container"><div id="fn7"><p><sup>7</sup>&nbsp;<a href="https://quoraengineering.quora.com/Optimizing-the-databases-at-Quora">Optimizing the databases at Quora</a></p></div></div><p><a href="https://www.timescale.com/blog/the-power-of-linked-data-event-streams-and-timescaledb-for-real-time-management-of-time-series-data/">The power of linked data event streams and timescale for real-time management of time-series data.</a></p>
<p>How to configure PGSnapper for better insights into the PostgreSQL performance on AWS.<sup>8</sup></p>
<div class="no-row-height column-margin column-container"><div id="fn8"><p><sup>8</sup>&nbsp;<a href="https://aws.amazon.com/blogs/database/monitor-amazon-rds-for-postgresql-and-amazon-aurora-postgresql-performance-using-pgsnapper/">Monitor Amazon RDS for PostgreSQL and Amazon Aurora PostgreSQL performance using PGSnapper</a></p></div></div><p><a href="https://engineering.adjust.com/post/11_tb_wal_in_postgresql/">11TB WAL in PostgreSQL</a></p>
<p>Designing a new ChunkStore for Dolt - a database that uses a storage engine inspired by Git.<sup>9</sup></p>
<div class="no-row-height column-margin column-container"><div id="fn9"><p><sup>9</sup>&nbsp;<a href="https://www.dolthub.com/blog/2023-03-08-dolt-chunk-journal/">Journaling Chunk Store</a></p></div></div></section>
<section id="business" class="level2">
<h2 class="anchored" data-anchor-id="business">Business</h2>
<p><a href="https://www.cockroachlabs.com/blog/5-fintech-companies-refused-to-sacrifice-scale-availability-or-consistency/">How 5 fintech companies build for scale, availability, and consistency.</a></p>
<p><a href="https://www.snowflake.com/blog/how-financial-services-mitigate-financial-crime-incidents/">Mitigating financial crime incidents in the financial services sector.</a></p>
<p><a href="https://ravendb.net/articles/how-to-boost-queries-by-800-without-abandoning-your-relational-system">How to boost queries by 800% without abandoning your relational system.</a></p>


</section>


 ]]></description>
  <guid>https://www.eliasnema.com/posts/newsletter/2023-03-10.html</guid>
  <pubDate>Fri, 10 Mar 2023 00:00:00 GMT</pubDate>
  <media:content url="https://www.eliasnema.com/posts/df2-small.png" medium="image" type="image/png"/>
</item>
<item>
  <title>Foundational Paper: The Transaction Concept</title>
  <dc:creator>Elias Nema</dc:creator>
  <link>https://www.eliasnema.com/posts/newsletter/2023-03-08-transactional-concept.html</link>
  <description><![CDATA[ 





<p><a href="https://jimgray.azurewebsites.net/papers/theTransactionConcept.pdf">“The Transaction Concept: Virtues and Limitations”</a> paper lays down the foundation for the transactions in computer systems. It describes the concepts of ACID (not yet acronymized in the paper), undo and redo logs, and design for highly available systems. I enjoyed the paper a lot. Simple language, analogies, and a look at history make it a stark contrast to many of the modern papers, where looking sophisticated is often more important than the substance.</p>
<p>As always, I start with the visual representation of the paper in which I distilled and connected the most important points:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://www.eliasnema.com/data-feed/paper-transactional-model/transactional-model-sm.png" class="img-fluid figure-img"></p>
<figcaption>Diagram: the concept of a transaction as described by Jim Gray in 1981.</figcaption>
</figure>
</div>
<p>But the paper itself is far more poetic. For example, from now on that’s the only acceptable history horizon to look back at a problem:</p>
<ul>
<li><em>“The legendary Greeks, Ariadne and Theseus, <strong>invented logging.</strong> Ariadne gave Theseus a magic ball of string which he unraveled as he searched the Labyrinth for the Minotaur. Having slain the Minotaur, Theseus followed the string back to the entrance rather then remaining lost in the Labyrinth. This string was his log allowing him to undo the process of entering the Labyrinth. But the Minotaur was not a protected object so its death was not undone by Theseus’ exit.”</em></li>
<li><em>“Hansel and Gretel copied Theseus’ trick as they wandered into the woods in search of berries. They left behind a trail of crumbs that would allow them to retrace their steps by following the trail backwards, and would allow their parents to find them by following the trail forwards. This was the first undo and redo log. Unfortunately, a bird ate the crumbs and caused <strong>the first log failure.</strong>”</em></li>
</ul>
<p>Gray talks about transactions in human terms, as derived from the contract law:</p>
<ul>
<li><em>“The Christian wedding ceremony gives a good example of such a contract. The bride and groom “negotiate” for days or years and then appoint a minister to conduct the marriage ceremony. The minister first asks if anyone has any objections to the marriage; he then asks the bride and groom if they agree to the marriage. If they both say, “I do”, he pronounces them man and wife.”</em></li>
</ul>
<p>He also comes up with <strong>Consistency, Atomicity, and Durability</strong> as properties of a transaction (<em>Isolation</em> is not yet explicitly mentioned, but the concept is described in the logging implementation):</p>
<ul>
<li><em>“If transactions run concurrently, one transaction might read the outputs (updates or messages) of another transaction. If the first transaction aborts, then undoing it requires undoing the updates or messages read by the second transaction. This in turn requires undoing the second transaction. But the second transaction may have already committed and so cannot be undone. To prevent this dilemma, real and protected updates (undoable updates) of a transaction <strong>must be hidden from other transactions until the transaction commits.</strong> To assure that reading two related records, or rereading the same record, will give consistent results, one must also stabilize records which a transaction reads and keep them constant until the transaction commits. Otherwise a transaction could reread a record and get two different answers.”</em></li>
</ul>
<p>Going back to Von Neumann for the concept of building reliable systems by adding redundancy to the systems:</p>
<ul>
<li><em>“John Von Neumann is credited with the observation that a very reliable (and available) system can be built from unreliable components. Von Neumann’ s idea was to use redundancy and majority logic on a grand scale (20,000 wires for one wire) in order to get mean- times-to-failure measured in decades. Von Neumann was thinking in terms of neurons and vacuum tubes which have mean-times-to-failures measured in days and which are used in huge quantities (millions or billions) in a system. In addition, Von Neumann’s model was flat so that any failure in a chain broke the whole chain.”</em></li>
</ul>
<p>I also haven’t realised how many of the transaction problems in computer come from the possibility of in-place updates:</p>
<ul>
<li><em>The advent of direct access storage (discs and drums) changed this. It was now possible to update only a part of a file. Rather than copying the whole disc whenever one part was updated, it became attractive to update just the parts that changed in order to construct the new master. Some of these techniques, notably side files and differential files did not update the old master and hence followed good accounting techniques. But <strong>for performance reasons, most disc-based systems have been seduced into updating the data in place.</strong></em></li>
</ul>
<p>And the importance of what now is popular to call <strong>idempotency:</strong></p>
<p><em>- “Another detail is that the <strong>undo and redo operations must be restartable,</strong> that is if the operation is already undone or redone, the operation should not damage or change the object state. The need for restartability comes from the need to deal with failures during undo and redo processing. Restartability is usually accomplished with version numbers (for disc pages) and with sequence numbers (for virtual circuits or sessions). Essentially, the undo or redo operation reads the version or sequence number and does nothing if it is the desired number. Otherwise it transforms the object and the sequence number.”</em></p>



 ]]></description>
  <guid>https://www.eliasnema.com/posts/newsletter/2023-03-08-transactional-concept.html</guid>
  <pubDate>Wed, 08 Mar 2023 00:00:00 GMT</pubDate>
  <media:content url="https://www.eliasnema.com/posts/df2-small.png" medium="image" type="image/png"/>
</item>
<item>
  <title>Data Feed #4: Vectors</title>
  <dc:creator>Elias Nema</dc:creator>
  <link>https://www.eliasnema.com/posts/newsletter/2023-03-03.html</link>
  <description><![CDATA[ 





<section id="focus-vectors" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="focus-vectors">Focus: Vectors</h2>
<p>Using open-source vector similarity extension for Postgres<sup>1</sup>:</p>
<div class="no-row-height column-margin column-container"><div id="fn1"><p><sup>1</sup>&nbsp;<a href="https://github.com/pgvector/pgvector">pgvector</a></p></div></div><ul>
<li><a href="https://www.crunchydata.com/blog/whats-postgres-got-to-do-with-ai">What’s Postgres Got To Do With AI?</a></li>
<li>Using postgres_scanner<sup>2</sup> to <a href="https://blog.eto.ai/vector-similarity-search-with-duckdb-44dec043532a">read vectors from PG in DuckDB</a>.</li>
</ul>
<div class="no-row-height column-margin column-container"><div id="fn2"><p><sup>2</sup>&nbsp;<a href="https://duckdb.org/docs/extensions/postgres_scanner.html">postgres_scanner</a></p></div><div id="fn3"><p><sup>3</sup>&nbsp;<a href="https://dl.acm.org/doi/pdf/10.1145/3318464.3386131">PASE: PostgreSQL Ultra-High-Dimensional Approximate Nearest Neighbor Search Extension</a></p></div></div><p>A detailed paper from SIGMOD’20<sup>3</sup> describes how Alibaba designed and built an approximate nearest neighbor search extension for vector similarity. Great deep dive into page structures for ANN indexes, and the <a href="https://github.com/alipay/PASE">code is even available</a> (though, not maintained).</p>
<p>Using vector functions in SingleStore’s SQL, but not clear how well the system scales since the example uses only 7000 vectors.<sup>4</sup></p>
<div class="no-row-height column-margin column-container"><div id="fn4"><p><sup>4</sup>&nbsp;<a href="https://www.singlestore.com/blog/using-vector-functions-image-matching-sql/">Image Matching in SQL with SingleStoreDB</a></p></div><div id="fn5"><p><sup>5</sup>&nbsp;<a href="https://aws.amazon.com/blogs/big-data/build-a-semantic-search-engine-for-tabular-columns-with-transformers-and-amazon-opensearch-service/">Build a semantic search engine for tabular columns with Transformers and Amazon OpenSearch Service</a></p></div></div><p>An amazing use-case (as far as I’m concerned, <a href="https://www.datagalaxy.com/en/blog/data-swamp-vs-data-lake/">data swamps</a> are real) of representing individual columns in the embedding space by utilising pre-trained transformer models. Then, using those vectors to find semantically similar data <em>within your data.</em><sup>5</sup></p>
</section>
<section id="learning" class="level2">
<h2 class="anchored" data-anchor-id="learning">Learning</h2>
<p><a href="https://aws.amazon.com/blogs/big-data/use-apache-iceberg-in-a-data-lake-to-support-incremental-data-processing/">Use Apache Iceberg in a data lake to support incremental data processing.</a></p>
<p><a href="https://aws.amazon.com/blogs/big-data/access-amazon-athena-in-your-applications-using-the-websocket-api/">Access Amazon Athena in your applications using the WebSocket API.</a></p>
<p><a href="https://crate.io/blog/guide-to-bitwise-operators-in-cratedb">Guide to bitwise operators in CrateDB.</a></p>
<p><a href="https://grafana.com/blog/2023/03/02/grafana-labs-webinars-reduce-mttr-build-beautiful-grafana-dashboards-and-more/">Grafana Labs webinars: Reduce MTTR, build beautiful Grafana dashboards, and more.</a></p>
<p><a href="https://blog.netdata.cloud/anomaly-detection-on-prometheus-metrics/#gsc.tab=0">Anomaly detection on Prometheus metrics.</a></p>
<p><a href="https://www.dolthub.com/blog/2023-03-01-change-data-capture/">So you want Change Data Capture?</a></p>
<p><a href="https://aws.amazon.com/blogs/big-data/patterns-for-enterprise-data-sharing-at-scale/">Patterns for enterprise data sharing at scale.</a></p>
</section>
<section id="deep-dive" class="level2">
<h2 class="anchored" data-anchor-id="deep-dive">Deep Dive</h2>
<p>A new lecture is out from the <a href="https://15721.courses.cs.cmu.edu/spring2023/">CMU Advanced Databases</a> course on <a href="https://www.youtube.com/watch?v=pqRV7Mss1Fg">Parallel Hash Join Algorithms</a>. If you are into data, you should have a very good reason for not watching this playlist.</p>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/pqRV7Mss1Fg" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</section>
<section id="business" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="business">Business</h2>
<p>Amazing (as always) write-up about using TimescaleDB in the wild, and why compression is crucial for the time-series databases.<sup>6</sup></p>
<div class="no-row-height column-margin column-container"><div id="fn6"><p><sup>6</sup>&nbsp;<a href="https://www.timescale.com/blog/how-ndustrial-is-providing-fast-real-time-queries-and-safely-storing-client-data-with-97-compression/">How Ndustrial Is Providing Fast Real-Time Queries and Safely Storing Client Data With 97 % Compression</a></p></div></div><p><a href="https://aws.amazon.com/blogs/database/how-wiz-used-amazon-elasticache-to-improve-performance-and-reduce-costs/">How Wiz used Amazon ElastiCache to improve performance and reduce costs.</a></p>
<p><a href="https://www.datadoghq.com/blog/delivery-hero-kubernetes-cost-optimization/">How Delivery Hero uses Kubecost and Datadog to manage Kubernetes costs in the cloud.</a></p>
<p>An emerging buzzword for data platforms capable of both transactions and analytics workloads – “translytical.” A webinar from SingleStore describes precisely such platforms.<sup>7</sup></p>


<div class="no-row-height column-margin column-container"><div id="fn7"><p><sup>7</sup>&nbsp;<a href="https://www.singlestore.com/blog/webinar-recap-real-time-data-and-the-state-of-translytical-platforms/">Webinar Recap: Real-Time Data and the State of Translytical Platforms</a></p></div></div></section>


 ]]></description>
  <guid>https://www.eliasnema.com/posts/newsletter/2023-03-03.html</guid>
  <pubDate>Fri, 03 Mar 2023 00:00:00 GMT</pubDate>
  <media:content url="https://www.eliasnema.com/posts/df2-small.png" medium="image" type="image/png"/>
</item>
<item>
  <title>Data Feed #3</title>
  <dc:creator>Elias Nema</dc:creator>
  <link>https://www.eliasnema.com/posts/newsletter/2023-02-23.html</link>
  <description><![CDATA[ 





<section id="learning" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="learning">Learning</h2>
<p>Compilation of the best Scylla articles and use-cases.<sup>1</sup></p>
<div class="no-row-height column-margin column-container"><div id="fn1"><p><sup>1</sup>&nbsp;<a href="https://www.scylladb.com/2023/02/21/scylladb-innovation-awards-honor-impressive-nosql-rust-low-latency-achievements/">ScyllaDB Innovation Awards + Rust Low-Latency Achievements</a></p></div><div id="fn2"><p><sup>2</sup>&nbsp;<a href="https://www.eliasnema.com/data-feed/2023-02-23.html#fn2">CrateDB aggregations</a></p></div></div><p>Addition to the CrateDB: <code>max/min_by(expr1, expr2)</code> - returns the value of an <code>expr1</code> associated with the max/min value of <code>expr2</code> in a group.<sup>2</sup></p>
<p><a href="https://redpanda.com/blog/build-streaming-data-pipeline-upsolver">How to build streaming data pipelines with Redpanda and Upsolver SQLake.</a></p>
<p><a href="https://aws.amazon.com/blogs/database/query-data-with-dynamodb-shell-a-command-line-interface-for-amazon-dynamodb/">Query data with DynamoDB Shell – a command line interface for Amazon DynamoDB</a></p>
<p>I first learned about Frits Hoogland from the world of Oracle. Now he is with YugabyteDB, and here is his profile in the person of the week <sup>3</sup> and an article from him about the high availability in Yugabyte.<sup>4</sup></p>
<div class="no-row-height column-margin column-container"><div id="fn3"><p><sup>3</sup>&nbsp;<a href="https://postgresql.life/post/frits_hoogland/">PostgreSQL Person of the Week - Frits Hoogland</a></p></div><div id="fn4"><p><sup>4</sup>&nbsp;<a href="https://dev.to/yugabyte/yugabytedb-how-does-a-master-deal-with-ha-o0p">YugabyteDB: how does a master deal with HA</a></p></div></div><p><a href="https://www.yugabyte.com/blog/distributed-database-transactional-consistency-async-standby/">Can Distributed Databases Achieve Transactional Consistency on Async Standbys? Yes, They Can.</a></p>
</section>
<section id="hacking" class="level2">
<h2 class="anchored" data-anchor-id="hacking">Hacking</h2>
<p>Postgres System Columns Explained (ctid, xmin,xmax) </p><div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/AveRgUrC7FM" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div><p></p>
<p>Index “do it yourself” - a 2020 PGCon talk from <a href="https://twitter.com/x4mmmmmm">Andrey Borodin</a>, plus you’ll get to know the scale of Postgres at Yandex.</p>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/NUJMcIwu9VY" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</section>
<section id="visualization" class="level2">
<h2 class="anchored" data-anchor-id="visualization">Visualization</h2>
<p><a href="https://grafana.com/blog/2023/02/24/introducing-the-xyz-chart-a-three-dimensional-way-to-visualize-your-data-in-grafana/">Introducing the XYZ chart: A three-dimensional way to visualize your data in Grafana.</a></p>
<p><a href="https://duckdb.org/2023/02/24/jupysql.html">JupySQL Plotting with DuckDB.</a></p>
<p><a href="https://datasette.io/tutorials/codespaces">Using Datasette in GitHub Codespaces.</a></p>
<p><a href="https://simonwillison.net/2023/Feb/17/analytics/">Analytics: Hacker News v.s. a tweet from Elon Musk.</a></p>
</section>
<section id="deep-dive" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="deep-dive">Deep Dive</h2>
<p>Practical walk-through on data modelling of IMDb dataset for the DynamoDB.<sup>5</sup></p>
<div class="no-row-height column-margin column-container"><div id="fn5"><p><sup>5</sup>&nbsp;<a href="https://aws.amazon.com/blogs/database/data-modelling-for-an-internet-scale-online-transactional-system-using-amazon-dynamodb/">Data modelling for an internet-scale online transactional system using Amazon DynamoDB</a></p></div><div id="fn6"><p><sup>6</sup>&nbsp;<a href="https://materialize.com/blog/materialize-architecture/">The Software Architecture of Materialize</a></p></div></div><p>Materialize is a SQL database built on top of streming solutions, here is a peek into the architecture.<sup>6</sup></p>
<p>Great Spark benchmarks for shuffle-intensive workloads.<sup>7</sup></p>
<div class="no-row-height column-margin column-container"><div id="fn7"><p><sup>7</sup>&nbsp;<a href="https://aws.amazon.com/blogs/big-data/amazon-emr-serverless-supports-larger-worker-sizes-to-run-more-compute-and-memory-intensive-workloads/">Amazon EMR Serverless supports larger worker sizes to run more compute and memory-intensive workloads</a></p></div></div><p><a href="http://smalldatum.blogspot.com/2023/02/sysbench-arm-x86-public-cloud.html">Sysbench, Arm &amp; x86, public cloud.</a></p>
</section>
<section id="business" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="business">Business</h2>
<p>Will artificial intelligence eat software and why invest in the database market?.<sup>8</sup></p>
<div class="no-row-height column-margin column-container"><div id="fn8"><p><sup>8</sup>&nbsp;<a href="https://www.datastax.com/blog/premji-invest-ai-future">Premji Invest: Artificial Intelligence Will Eat Software</a></p></div><div id="fn9"><p><sup>9</sup>&nbsp;<a href="https://www.snowflake.com/blog/startup-spotlight-api-on-top-of-snowflake-propel/">Startup Spotlight: APIs on Top of Snowflake with Propel</a></p></div></div><p>Interesting company building an API platform for developers to build apps on top of their data easier.<sup>9</sup></p>


</section>


 ]]></description>
  <guid>https://www.eliasnema.com/posts/newsletter/2023-02-23.html</guid>
  <pubDate>Thu, 23 Feb 2023 00:00:00 GMT</pubDate>
  <media:content url="https://www.eliasnema.com/posts/df2-small.png" medium="image" type="image/png"/>
</item>
<item>
  <title>Engineering Managers should Product et al.</title>
  <dc:creator>Elias Nema</dc:creator>
  <link>https://www.eliasnema.com/posts/product-engineering/product-engineering.html</link>
  <description><![CDATA[ 





<p><strong>Summary: software engineers (especially leaders/managers up the tech hierarchy) should spend more time closer to the business, product, and marketing. They should treat it as part of their main responsibilities, not a nice-to-haves or if-have-times (which, of course, no one ever does).</strong></p>
<p>Some time ago, a tweet from Shreyas confirmed something I’ve also seen a lot – software engineering leadership focuses on technical problems, leaving business discussions to <em>“the business”,</em> or, more recently to <em>“the product”.</em> If not totally abandoning, then at least not thinking about this as a part of their main job – waiting for these magical stakeholders to have all the answers ready, while engineering will be focusing on tech things, prioritising tech debt, building internal tools, or what have you. I’m curious <strong>1/</strong> if that’s a software industry phenomenon, <strong>2/</strong> why is that happening, and <strong>3/</strong> what should engineers do, depending on the environment they are in.</p>
<center>
<blockquote class="twitter-tweet blockquote">
<p lang="en" dir="ltr">
I am increasingly of the opinion that engineering leaders &amp; design leaders should be putting more pressure on their PM counterparts to <em>help devise</em> a sound product strategy. And this is absolutely vital if the business has been struggling. More process won’t solve this problem.
</p>
— Shreyas Doshi (<span class="citation" data-cites="shreyas">@shreyas</span>) <a href="https://twitter.com/shreyas/status/1616874874349445121?ref_src=twsrc%5Etfw">January 21, 2023</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</center>
<section id="software" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="software">Software</h2>
<section id="stage-1-support-function" class="level3">
<h3 class="anchored" data-anchor-id="stage-1-support-function">Stage 1: Support Function</h3>
<p>In the early days of computers, IT was separate from business and played the role of a supporting function to automate some business processes and provide better business insights. Business innovations were happening outside the “computers”, and business is not growing by optimising and investing in software.</p>
<p>IT, as a support function, operates in a “ticketing machine” environment where things are regulated or already defined. An operational model of “just do what business tells” prevails and is also appropriate for such a setup.</p>
</section>
<section id="stage-2-transition-period-support-core" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="stage-2-transition-period-support-core">Stage 2: Transition Period (Support → Core)</h3>
<p>Later on, software started percolating all the various areas of business and life and started to – famously – <strong>eat the world.</strong></p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>I don’t like this phrasing. It assumes that the endgame is only software, while I believe that the hardware will always be equally important, as proved recently by Apple and others – without the underlying layers, there will be nothing to build on top of.</p>
</div>
</div>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="https://www.eliasnema.com/posts/product-engineering/going-soft.png" class="img-fluid figure-img" style="width:35.0%"></p>
<figcaption class="margin-caption">But regardless of the name, it’s still happening and going to continue in the <a href="https://www.economist.com/business/2022/06/12/how-supply-chain-turmoil-is-remaking-the-car-industry">foreseeable future.</a></figcaption>
</figure>
</div>
<p>This triggered a transition for software from a cost to a profit centre. It also exposed the ineffectiveness of the methods using rigid requirements and specifications, which, among other things, triggered the development of agile methodologies in software. These methods, however, attempted to fix the problem by establishing better interfaces between stakeholders. <strong>There was still a separation between the people who own the requirements, and the ones who implement them.</strong> However, this sets a trend of reducing dependencies and communication bottlenecks across different parts of building products.</p>
<p>But there is also an opposite force at work at the same time – software becomes more complex. This drives <strong>specialisation and more vertical knowledge.</strong> Technical experts need to go deeper and deeper to understand their topics at the same level. This, in turn, drives separation and creates a talent gap, where there are not enough people experienced in both technology and business. For example, Amazon was one of the first companies that separated the roles of product and engineering leadership, because it was hard to find people that were good at both.</p>
</section>
<section id="stage-3-software-is-product" class="level3">
<h3 class="anchored" data-anchor-id="stage-3-software-is-product">Stage 3: Software is Product</h3>
<p>This brings us to the period of more mature software products and development environments. It removes more interfaces and awards the role of the final judge to the <strong>customer.</strong> Software becomes a product in itself. There are even products <a href="https://blog.symops.com/2023/01/05/platform-engineering-as-a-startup/">within products.</a></p>
<p>Elimination of more silos is happening. DevOps, SREs, and continuous delivery movements, with cloud-enabling this transition on the underlying layer, removed final barriers between development, testing, and infrastructure. Engineering teams started working together to deliver a product and not a set of functional competencies.</p>
<p>We’ve learned to build software relatively fast and of good quality. However, we still do not always build what is needed for the user. The last gap standing is between engineering and business. This gap is responsible for creating engineering silos, <strong>software platforms that cannot support unit economics of business,</strong> and engineering for the sake of engineering, where you end up with systems inappropriately built for the size and scale of the business (no matter up or down), and cargo-culting with the best practices not adding value in a particular situation.</p>
<p>The reality is not evenly distributed, of course. Still, it’s happening way <a href="https://twitter.com/SergioRocks/status/1622959677431775235">too often</a> (so much that the opinion is still unpopular) in companies of all shapes and sizes. A lot of time business finds themselves <strong>hostage</strong> to tech decisions, not realising before that those decisions are actually business decisions now.</p>
<center>
<blockquote class="twitter-tweet blockquote">
<p lang="en" dir="ltr">
to connect services to business through data.<br><br>"Business processes and domains were subordinate to applications."<br><br>This resonates, and I've multiple times seen the business end up hostage to the tech stack at some point in a company's evolution.
</p>
— Elias (<span class="citation" data-cites="eliasnema">@eliasnema</span>) <a href="https://twitter.com/eliasnema/status/1620543538772705280?ref_src=twsrc%5Etfw">January 31, 2023</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</center>
</section>
</section>
<section id="other-industries" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="other-industries">Other industries</h2>
<p>At the beginning of my career, I worked in a couple of mechanical engineering companies, producing “real” objects. The environments I experienced there were a bit different from software, of course, but generally, engineers were <strong>not much closer</strong> to the product and business decisions. There were also no product managers to support them and close the gap.</p>
<p>This, however, still resulted in less over-engineered solutions or products that were completely off than I’ve seen working in software. But one explanation of this might be that when building physical products we have more constraints from the real world, while the <strong>possibility space is much wider</strong> with software. This increases variability in opinions and potential solution space, which makes communication through specifications even harder.</p>
<p>But going back in history, it turns out, that as with many problems, this one is also not new at all. Businesses started experiencing similar problems at least 70 years back when tech had yet nothing to do with software. Recently, I stumbled upon <a href="https://dl.acm.org/doi/10.1145/1434821.1434825">this paper from 1951</a> describing the changing role of management.</p>
<p>What’s fascinating is that already back then, the author notices that management nature changes, with factors such as human capital, research, and marketing starting to play as crucial of a role as science and engineering. <a href="../../posts/management-history/management-history.html">Here are more</a> quotes and thoughts from it.</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><a href="../management-history/mgmt-history.png"><img src="https://www.eliasnema.com/posts/management-history/mgmt-history.png" class="img-fluid figure-img"></a></p>
<figcaption class="margin-caption">Visual representation of 1951’s ‘New equations for management’</figcaption>
</figure>
</div>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>I don’t think that all companies will or should turn into software product companies. But you need to understand the environment you are in. And to converge sooner from Stage 2 to either 1 (cost) or 3 (profit).</p>
<p>The two competing factors in tech and management overall are not going away any time soon: tech still develops rapidly, complexity continues to grow, which drives <strong>specialisation.</strong> On the other hand, this leaves even less room for the defined requirements and specs, hence, creating a pull for <strong>cross-functional specialists.</strong></p>
<p>The main task of an engineering team is to deliver a product, of course. And your goal as a leader is <strong>to ensure this delivery.</strong> For this, you need to understand technology and engineering. But if the business you are working on has engineering at its core, your responsibilities stretch much further than just that:</p>
<ul>
<li>Understand <strong>people,</strong> and their motivations and build connections (this aspect is more universally accepted now).</li>
<li>Understand where your team’s value creation is happening in the <strong>business and marketing cycle.</strong></li>
<li>Tie the <strong>tech stack to the business decisions</strong> and make sure your team’s progress metrics are connected to the success of the overall company, not just the software development progress.</li>
<li><strong>Proactively build connections</strong> with product, marketing, legal, etc., or partially cover those roles yourself. Depending on the company you might have dedicated managers leading those directions, but that’s part of your role to proactively work with them on the engineering and business strategies.</li>
</ul>


</section>

 ]]></description>
  <category>engineering</category>
  <category>leadership</category>
  <guid>https://www.eliasnema.com/posts/product-engineering/product-engineering.html</guid>
  <pubDate>Sun, 19 Feb 2023 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Data Feed #2</title>
  <dc:creator>Elias Nema</dc:creator>
  <link>https://www.eliasnema.com/posts/newsletter/2023-02-17.html</link>
  <description><![CDATA[ 





<section id="learning" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="learning">Learning</h2>
<p>Fantastic content all around from both days of the ScyllaDB Summit: <a href="https://www.scylladb.com/2023/02/15/scylladb-summit-day-1-nosql-at-scalewith-less/">Day 1</a>, <a href="https://www.scylladb.com/2023/02/16/scylladb-summit-day-2-continuing-the-high-performance-nosql-conversation/">Day 2</a></p>
<p><a href="https://www.cockroachlabs.com/blog/distributed-transactions-what-why-and-how-to-build-a-distributed-transactional-application/">Distributed transactions: What, why, and how to build a distributed transactional application.</a></p>
<section id="replication" class="level4">
<h4 class="anchored" data-anchor-id="replication">Replication</h4>
<ul>
<li><p><a href="https://aws.amazon.com/blogs/database/improve-logical-replication-performance-in-amazon-aurora-postgresql-with-the-new-write-through-cache/">Improve logical replication performance in Amazon Aurora PostgreSQL with the new write-through cache.</a></p></li>
<li><p><a href="https://docs.dolthub.com/guides/binlog-replication">Dolt binlog replication from a MySQL or MariaDB.</a></p></li>
</ul>
</section>
<section id="tips" class="level4 page-columns page-full">
<h4 class="anchored" data-anchor-id="tips">Tips</h4>
<ul>
<li><p>Working with JSON data, using monitoring, and connecting to Dremio in SingleStoreDB.<sup>1</sup></p></li>
<li><p>Data modelling and queries considerations at RavenDB.<sup>2</sup></p></li>
<li><p><a href="https://crate.io/blog/guide-to-sharding-and-partitioning-best-practices-in-cratedb">Guide to sharding and partitioning best practices in CrateDB.</a></p></li>
</ul>
<div class="no-row-height column-margin column-container"><div id="fn1"><p><sup>1</sup>&nbsp;<a href="https://www.singlestore.com/blog/developer-quick-tips/">Developer Quick Tips</a></p></div><div id="fn2"><p><sup>2</sup>&nbsp;<a href="https://ravendb.net/articles/recording-ravendb-usage-patterns">Recording: RavenDB Usage Patterns</a></p></div></div></section>
</section>
<section id="hacking" class="level2">
<h2 class="anchored" data-anchor-id="hacking">Hacking</h2>
<p>As always fantastic and informative video from <a href="https://twitter.com/x4mmmmmm">Andrey Borodin</a> about detailed buffers statistics in EXPLAIN BUFFERS:</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/36n49jjfPo8" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="">
</iframe>
</section>
<section id="deep-dive" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="deep-dive">Deep Dive</h2>
<p>Insightful analysis of implementing comparing data sampling implementation in DB versus on the client.<sup>3</sup></p>
<div class="no-row-height column-margin column-container"><div id="fn3"><p><sup>3</sup>&nbsp;<a href="https://www.timescale.com/blog/downsampling-in-the-database-how-data-locality-can-improve-data-analysis/">Downsampling in the Database: How Data Locality Can Improve Data Analysis</a></p></div><div id="fn4"><p><sup>4</sup>&nbsp;<a href="https://clickhouse.com/blog/five-methods-of-database-obfuscation">Five Methods For Database Obfuscation</a></p></div></div><p>Article from Alexey Milovidov himself, that stretches over quite a long period of time and describes ClickHouse journey to the data obfuscation.<sup>4</sup></p>
<p>Short a sweet deep dive into Postgres Write Ahead Log (WAL) files and Log Sequence numbers (LSN).<sup>5</sup></p>
<div class="no-row-height column-margin column-container"><div id="fn5"><p><sup>5</sup>&nbsp;<a href="https://www.crunchydata.com/blog/postgres-wal-files-and-sequuence-numbers">Postgres WAL Files and Sequence Numbers</a></p></div></div></section>
<section id="business" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="business">Business</h2>
<p><a href="https://www.cockroachlabs.com/blog/real-money-gaming-cost-savings/">Real-money gaming company saves $1.5 million per regional expansion with CockroachDB.</a></p>
<p>A very interesting case from a <a href="https://everactive.com">company</a> producing batteryless sensors, that continuously stream data used in all kind of manufactoring industries (chemical processing, district energy, rotating equipment – motors, pumps, fans, compressors, etc.)<sup>6</sup></p>
<div class="no-row-height column-margin column-container"><div id="fn6"><p><sup>6</sup>&nbsp;<a href="https://www.timescale.com/blog/how-everactive-powers-a-dense-sensor-network-with-virtually-no-power-at-all/">How Everactive Powers a Dense Sensor Network With Virtually No Power at All</a></p></div></div><p><a href="https://influx.com/blog/year-summary-2022">Influx year in review 2022.</a></p>


</section>


 ]]></description>
  <guid>https://www.eliasnema.com/posts/newsletter/2023-02-17.html</guid>
  <pubDate>Fri, 17 Feb 2023 00:00:00 GMT</pubDate>
  <media:content url="https://www.eliasnema.com/posts/df2-small.png" medium="image" type="image/png"/>
</item>
<item>
  <title>Data Feed #1</title>
  <dc:creator>Elias Nema</dc:creator>
  <link>https://www.eliasnema.com/posts/newsletter/2023-02-10.html</link>
  <description><![CDATA[ 





<section id="learning" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="learning">Learning</h2>
<p><a href="https://twitter.com/andy_pavlo">The Professor</a> explains how the replication works in AWS RDS and Aurora at the high level.<sup>1</sup></p>
<div class="no-row-height column-margin column-container"><div id="fn1"><p><sup>1</sup>&nbsp;<a href="https://ottertune.com/blog/how-amazon-rds-replication-works-and-why-the-faas-database-problem-wont-happen-in-aws/">How Amazon RDS Replication Works and Why the FAA’s Database Problem Won’t Happen in AWS</a></p></div><div id="fn2"><p><sup>2</sup>&nbsp;<a href="https://planetscale.com/blog/migrating-from-postgres-to-mysql">Migrating from Postgres to MySQL</a></p></div></div><p>Great guide about what to look at when migrating from Postgres to MySQL.<sup>2</sup></p>
<p><a href="https://redis.com/blog/database-developers-conferences-2023/">The Top Conferences for Database Developers to Attend in 2023.</a></p>
</section>
<section id="hacking" class="level2">
<h2 class="anchored" data-anchor-id="hacking">Hacking</h2>
<p>Wonderful 101 PostgreSQL hacking with implementing two simple patches live.</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/samLkrC5xQA" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="">
</iframe>
<iframe width="560" height="315" src="https://www.youtube.com/embed/YPq_hiOE-N8" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="">
</iframe>
</section>
<section id="deep-dive" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="deep-dive">Deep Dive</h2>
<p><a href="https://twitter.com/muratdemirbas">Murat</a> looks at a <a href="https://stratos.seas.harvard.edu/files/stratos/files/rum.pdf">The RUM Conjecture paper</a>, describing read times/update cost/memory overhead trade-offs.<sup>3</sup></p>
<div class="no-row-height column-margin column-container"><div id="fn3"><p><sup>3</sup>&nbsp;<a href="http://muratbuffalo.blogspot.com/2023/02/designing-access-methods-rum-conjecture.html">Designing Access Methods: The RUM Conjecture</a></p></div></div></section>
<section id="history" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="history">History</h2>
<p>Graphs are at their peak popularity and (machine) learning overtook (data) mining in the analysis of words in database papers.<sup>4</sup></p>
<div class="no-row-height column-margin column-container"><div id="fn4"><p><sup>4</sup>&nbsp;<a href="https://databasearchitects.blogspot.com/2023/02/five-decades-of-database-research.html?m=1">Five Decades of Database Research</a></p></div></div><p><a href="https://www.timescale.com/blog/timescale-timeout-the-history-and-basics-of-postgresql-part-i/">The History and Basics of PostgreSQL.</a></p>
</section>
<section id="tutorials" class="level2">
<h2 class="anchored" data-anchor-id="tutorials">Tutorials</h2>
<p><a href="https://redpanda.com/blog/introduction-apache-camel-redpanda">Getting started with Apache Camel and Redpanda.</a></p>
<p><a href="https://www.scylladb.com/2023/02/08/scylladb-summit-preview-through-the-speakers-eyes/">ScyllaDB Summit Preview: Through the Speakers’ Eyes.</a></p>
<p><a href="https://www.dolthub.com/blog/2023-02-08-dolt-for-gamedev/">Version control for Video Game Development using Dolt.</a></p>
<p><a href="https://www.cockroachlabs.com/blog/what-is-data-partitioning-and-how-to-do-it-right/">What is data partitioning, and how to do it right.</a></p>
</section>
<section id="business" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="business">Business</h2>
<p>A good sneak peek into designing a payment processor from the database perspective.<sup>5</sup></p>
<div class="no-row-height column-margin column-container"><div id="fn5"><p><sup>5</sup>&nbsp;<a href="https://www.cockroachlabs.com/blog/cockroachdb-payments-system-architecture/">How to build a payments system that scales to infinity (with examples)</a></p></div><div id="fn6"><p><sup>6</sup>&nbsp;<a href="https://www.youtube.com/watch?v=LTpVTr0yLZo">RedisDays India: Redis Beyond Cache for E-Commerce</a></p></div></div><p>Learn how Meesho uses Redis (and not only) to achieve 30ms p99 latency with &gt; 1M peak requests per second.<sup>6</sup></p>


</section>


 ]]></description>
  <guid>https://www.eliasnema.com/posts/newsletter/2023-02-10.html</guid>
  <pubDate>Fri, 10 Feb 2023 00:00:00 GMT</pubDate>
  <media:content url="https://www.eliasnema.com/posts/df2-small.png" medium="image" type="image/png"/>
</item>
<item>
  <title>Paper: ‘New equations for management’, J. E. Hobson, 1951</title>
  <dc:creator>Elias Nema</dc:creator>
  <link>https://www.eliasnema.com/posts/management-history/management-history.html</link>
  <description><![CDATA[ 





<p><em>My graphical representation of the <a href="https://dl.acm.org/doi/10.1145/1434821.1434825">paper</a>:</em></p>
<div class="quarto-figure quarto-figure-right">
<figure class="figure">
<p><a href="mgmt-history.png"><img src="https://www.eliasnema.com/posts/management-history/mgmt-history.png" class="img-fluid quarto-figure quarto-figure-right figure-img"></a></p>
</figure>
</div>
<p>Really interesting to see how research came into a “normal” state of business. I thought such things mich come naturally to the business as a market pull. However, you can see the role individual and government incentives have played to create the environment that would set up American companies for success for the next century.</p>
<blockquote class="blockquote">
<ul>
<li>Before most industrialists had given much thought to systematic efforts toward invention, Edison was keeping 75 men busy conducting experiments and designing and building new electrical apparatus so that he could make the use of electricity practical.</li>
<li>The rise of industrial research during the past thirty years as a factor in the management equation was brought about, or at least was accelerated, by a number of well planned actions outside of industry itself.
<ul>
<li>During the decade of the twenties, the National Research Council, through its Division of Engineering, conducted an organized promotional program designed to show industry why it should support applied research in its own interest.</li>
<li>Furthermore, the Department of Commerce, under Mr.&nbsp;Hoover’s Secretaryship, began a long-term effort to encourage American industry to engage in and support applied research.</li>
<li>One other major development should be mentioned. The first independent non-profit organization set up to provide research services to industry, the Mellon Research Foundation, came into being in 1915.</li>
</ul></li>
</ul>
</blockquote>
<p>Very interesting to see the logical sequence leading to the creation of “tech”: scarcity → abundance → need marketing to sell → more complex and fact-driven products → requires cross-functional collaboration → “techno-economics”.</p>
<blockquote class="blockquote">
<ul>
<li>The use of automatic machinery resulted in tremendous increases in productivity per man … [which gave birth to] the idea of mass production, lower unit profits, lower prices, mass consumption, higher wages, and generally speaking, higher net profits.</li>
<li>marketing had to be changed from one of “order taking” to one of aggressive selling to the mass market. Some of the great names in business over the last few decades are to</li>
<li>This marketing revolution brought with it a new need for an organized approach to fact-finding—economic and market research. The idea developed slowly—first in the eastern part of our country, then in the West. As industry has become more and more complex from a technological standpoint, the research functions in economics and in the physical sciences and engineering have inevitably been brought closer together. The resulting approach is now known in some quarters as “techno-economics.”</li>
</ul>
</blockquote>
<p>This also drives the change in the organisational structures, creating the demand for the development of the data industry:</p>
<blockquote class="blockquote">
<ul>
<li>As the size, complexity, and scope of industrial operations increased, there developed gradually a wholesale separation between management and ownership in much the same sense that labor and management divided at the beginning of the Industrial Revolution.</li>
<li>New types of instrumentation and devices of all sorts are being created to produce more complex products in greater quantities at lower cost.</li>
<li>The economist, the marketing research specialist, and the statistician are teamed with engineers, scientists, and mathematicians to refine the marketing factor in the management equation to a more exact point.</li>
<li>In human relations, management is seeking new ways to appreciate, understand, and evaluate motivations, reactions, group dynamics, and human engineering problems, whether they involve workers, executives, customers, or the general public.</li>
<li>effectiveness of communication, the quality of leadership, the temper of employee morale, the adjustment of men to machines and of machines to men, and the significance of the working environment can be analyzed, interpreted, and predicted.</li>
<li>This trend brings an ever-widening and more urgent demand on the part of management - for facts—economic facts about production costs and schedules, market potentials and requirements, inventories and prices; - technical facts about new products and processes; - and social science facts about people and their patterns of behavior.</li>
</ul>
</blockquote>
<p>Considering recent tech layoffs and general rethinking of the effectiveness of latge orgs, this quote is quite timely:</p>
<blockquote class="blockquote">
<p>In attempting to achieve a more efficient operation to go along with the increasing complexity of industrial affairs, management has also given serious thought during recent years to the size and location of its organizational units. We hear more about the problem of size versus morale and efficiency. Some companies have taken the position that definite limits should be placed upon the size of a single operating group. Others are striving to place parts of their organization in suburban settings.</p>
</blockquote>
<p>Administrative revolution …</p>
<blockquote class="blockquote">
<p>it is conceivable that future business historians will know this period as the beginning of the “administrative revolution.”</p>
</blockquote>
<p>Here is also a thread with a few more excerpts:</p>
<blockquote class="twitter-tweet blockquote">
<p lang="en" dir="ltr">
With seemingly lots of mismanagement happening recently, I got curious about the history of management, and found the industry view from 1951 - a paper called "New equations for management".<br>Here is a visual summary I made, and a few excerpts from the paper I found interesting / <a href="https://t.co/kMYTWI4PSl">pic.twitter.com/kMYTWI4PSl</a>
</p>
— Elias Nema (<span class="citation" data-cites="eliasnema">@eliasnema</span>) <a href="https://twitter.com/eliasnema/status/1621149904424013824?ref_src=twsrc%5Etfw">February 2, 2023</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>



 ]]></description>
  <category>engineering</category>
  <category>leadership</category>
  <guid>https://www.eliasnema.com/posts/management-history/management-history.html</guid>
  <pubDate>Fri, 03 Feb 2023 00:00:00 GMT</pubDate>
</item>
<item>
  <title>📜 History (of Data Platforms and Apps)</title>
  <dc:creator>Elias Nema</dc:creator>
  <link>https://www.eliasnema.com/posts/newsletter/2020-10-06-newsletter-data-platforms.html</link>
  <description><![CDATA[ 





<section id="history-of-data-platforms-and-apps" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="history-of-data-platforms-and-apps">History (of Data Platforms and Apps)</h2>
<p>What’s the history of data-intensive applications and how did we end in a state where machines can classify cats better than us?</p>
<section id="softhardware-history-through-the-lens-of-ai" class="level3">
<h3 class="anchored" data-anchor-id="softhardware-history-through-the-lens-of-ai">[Soft/Hard]ware History through the Lens of AI</h3>
<p>An <a href="https://hardwarelottery.github.io/">interesting take at</a> a hardware-software intersection through the lens of AI applications. Some things that I found particularly fascinating:</p>
<blockquote class="blockquote">
<p>This essay begins by acknowledging a crucial paradox: machine learning researchers mostly ignore hardware despite the role it plays in determining what ideas succeed.</p>
</blockquote>
<ul>
<li>Computing started with <strong>single-purpose</strong> machines.</li>
<li>Then, in 1969, the general-purpose era began. This meant any move for the application-specific hardware was economically unfeasible because the <strong>performance benefit would fade away</strong> within 1-2 years with an ever-increasing number of transistors.</li>
</ul>
<blockquote class="blockquote">
<p>The few attempts to deviate and produce specialized supercomputers for research were financially unsustainable and short-lived.</p>
</blockquote>
<ul>
<li>However, there was a silver lining for specialized hardware. <strong>Von Neumann Bottleneck</strong> — the available compute is restricted by “the lone channel between the CPU and memory along which data has to travel sequentially”. Hence, in the 2000s GPUs were repurposed to be used with ML applications.</li>
<li>In 2012 Google <a href="https://arxiv.org/abs/1112.6209">used <strong>16,000 CPU cores to classify cats</strong></a>. In a year, the same task <a href="http://proceedings.mlr.press/v28/coates13.html">was completed with only <strong>2 CPU cores and 4 GPUs</strong></a>.</li>
<li>Hardware is only economically viable if the lifetime of the use case <strong>lasts more than three years</strong>. Hence, it already makes sense to build specific hardware for matrix multiplication for quite some time. Next come the unstructured sparsity and weight-specific quantization (what GPU manufacturers <a href="https://developer.nvidia.com/blog/nvidia-ampere-architecture-in-depth/">are recently doing</a>).</li>
<li>The rate of return for additional parameters is decreasing (e.g.&nbsp;Inception V3/ V4: <strong>21.8 vs 41.1 million parameters, 78.8 vs 80 % accuracy</strong>).</li>
<li>The training costs of GPT-3 is estimated to exceed <strong>$12 million dollars.</strong></li>
</ul>
</section>
<section id="a-brief-history-of-machine-learning-platforms" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="a-brief-history-of-machine-learning-platforms">A Brief History of Machine Learning Platforms</h3>
<p>No Hadoop, no AWS — barbarian days. Check out the <a href="https://databaseline.tech/a-brief-history-of-ml-platforms/">full timeline here</a>, it’s quite fun.</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="https://www.eliasnema.com/posts/newsletter/2020-10-06-ml-history-start.png" class="figure-img" width="300"></p>
<figcaption class="margin-caption">Pre-cloud Timeline</figcaption>
</figure>
</div>
</section>
<section id="is-data-hype-real" class="level3">
<h3 class="anchored" data-anchor-id="is-data-hype-real">Is Data Hype Real</h3>
<p><a href="https://medium.com/northzone/unpacking-the-data-hype-8c3a0ae63564">Another article</a> looking at different branches developed in a field of modern data processing. Describes prominent players in areas of data pipelines, catalogs, collaboration and quality.</p>
<blockquote class="blockquote">
<p><em>In 2010, the number of large enterprises with a Chief Data Officer (CDO) was 15. By&nbsp;<a href="https://medium.com/datapace/the-number-of-chief-data-officer-is-rising-but-this-role-is-still-unclear-be6add07315b">2017, it was up to 4,000</a>. In 2020, it’ll be over 10,000. Why? Data is revenue and revenue is sexy.</em></p>
</blockquote>
</section>
<section id="state-of-ai" class="level3">
<h3 class="anchored" data-anchor-id="state-of-ai">State of AI</h3>
<p>Yearly <a href="https://www.stateof.ai/">state of the AI report</a>. Here are some excerpts from the executive summary (page 7 of the report):</p>
<ul>
<li>The hottest area in AI: still <strong>NLP</strong></li>
<li>Closed AI — only <strong>15%</strong> of papers publish their code</li>
<li>Biology starts to benefit from AI (the <strong>first AI discovered drug</strong>)</li>
<li>Corporate-driven academic <strong>brain drain</strong></li>
<li><strong>US and China</strong> lead the AI research</li>
<li>Specialized hardware investments (see the hardware lottery article above). <strong>Semiconductor companies</strong> become more and more important.</li>
<li>Two <strong>wrong arrests</strong> using facial recognition.</li>
</ul>
</section>
</section>
<section id="ml-ops" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="ml-ops">ML Ops</h2>
<p>One of the hottest buzzwords in a room. However, I believe, this (and not the mysterious ML platforms) will <strong>close the gap in the adoption of ML applications and bring the power of data to the rest of us.</strong></p>
<section id="microsoft" class="level3">
<h3 class="anchored" data-anchor-id="microsoft">Microsoft</h3>
<p>Microsoft continues to do an amazing job for the ML community. Now with the GitHub as well. There is a <a href="https://github.blog/2020-10-01-keeping-your-data-pipelines-healthy-with-the-great-expectations-github-action/">second part</a> (<a href="https://github.blog/2020-06-17-using-github-actions-for-mlops-data-science/">part 1</a>) of the series related to the ML Ops — what data ops should have become. Integration with github actions is amazing and now supports The Great Expectations <a href="https://github.com/marketplace/actions/great-expectations-data">action</a> (which is an awesome <a href="https://greatexpectations.io/">project</a> in itself). &gt; <em>GitHub Actions don’t just do CI/CD, they provide powerful and flexible automation for ML engineers and data scientists.</em></p>
</section>
<section id="whylogs" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="whylogs">WhyLogs</h3>
<p>Much of the difficulty in maintaining an ML system comes from data drift. <a href="https://medium.com/whylabs/whylogs-embrace-data-logging-a9449cd121d">WhyLogs</a> calculates approximate statistics for datasets of any size up to TB-scale. Available in both Python and Java.</p>
<p>Here is a data distribution over time from the <a href="https://www.notion.so/771525fbe58c4151a79e8711a99f0fab">example</a> walkthrough:</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="https://www.eliasnema.com/posts/newsletter/2020-10-06-why-logs.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">why-logs</figcaption>
</figure>
</div>


</section>
</section>

 ]]></description>
  <category>data-meets-product</category>
  <guid>https://www.eliasnema.com/posts/newsletter/2020-10-06-newsletter-data-platforms.html</guid>
  <pubDate>Mon, 05 Oct 2020 23:00:00 GMT</pubDate>
</item>
<item>
  <title>⚖️ Democracy and ⚡ Efficiency</title>
  <dc:creator>Elias Nema</dc:creator>
  <link>https://www.eliasnema.com/posts/newsletter/2020-09-28-newsletter-democracy-efficiency.html</link>
  <description><![CDATA[ 





<section id="democracy-and-efficiency" class="level2">
<h2 class="anchored" data-anchor-id="democracy-and-efficiency">Democracy and Efficiency</h2>
<p>The AI has already proven to work well for many tasks that were not possible to tackle with computers before. Now we’ve entered the scaling phase to make it:</p>
<ul>
<li>as accessible as possible (developer tools, explainability, the <strong>“democratization of ML”</strong>) and</li>
<li>putting it on as many devices (<strong>model efficiency</strong>) as possible.</li>
</ul>
<p>Hence, more and more ready-to-use recipes are created, frameworks are hiding complexity, and, pre-built models are optimized and ready to be served on all kind of devices.</p>
</section>
<section id="recommendations" class="level2">
<h2 class="anchored" data-anchor-id="recommendations">Recommendations</h2>
<section id="tfrs" class="level3">
<h3 class="anchored" data-anchor-id="tfrs">TFRS</h3>
<p>This one is huge for the RecSys community. Google adds recommendations package into the tensorflow, <em>that makes building, evaluating, and serving sophisticated recommender models easy</em> (this is to the point of democracy).</p>
<p>This also involves <a href="https://twitter.com/maciej_kula?lang=en">Maciej Kula</a>, author of a couple of hugely popular reco libraries: <a href="https://github.com/lyst/lightfm">LightFM</a> and <a href="https://github.com/maciejkula/spotlight">Spotlight</a>. So it promises to be a very elegant API.</p>
<p>And you can see how easy it is to create even a <a href="https://www.tensorflow.org/recommenders/examples/multitask">multitask-system</a>. Here is a code snippet to define two learning tasks, one to predict ratings, another to predict the amount of relevant movies:</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1">tfrs.tasks.Ranking(</span>
<span id="cb1-2">    loss<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>tf.keras.losses.MeanSquaredError(),</span>
<span id="cb1-3">    metrics<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[tf.keras.metrics.RootMeanSquaredError()],</span>
<span id="cb1-4">)</span>
<span id="cb1-5"></span>
<span id="cb1-6">tfrs.tasks.Retrieval(</span>
<span id="cb1-7">    metrics<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>tfrs.metrics.FactorizedTopK(</span>
<span id="cb1-8">        candidates<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>movies.batch(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">128</span>)</span>
<span id="cb1-9">    )</span>
<span id="cb1-10">)</span></code></pre></div>
<p>Then you can combine these tasks while computing the loss and adjust the weight accordingly. It’s like Lego for recommendations.</p>
</section>
<section id="linkedins-intents" class="level3">
<h3 class="anchored" data-anchor-id="linkedins-intents">LinkedIn’s Intents</h3>
<p>A couple of years ago, LinkedIn has joined a cohort of companies that are doing recommendations by intent (members, pages, hashtags, newsletters, etc. in this case) on the main page. Here is a <a href="https://engineering.linkedin.com/blog/2020/helping-members-discover-communities-around-interests">story of how they did it</a>. Some highlights:</p>
<ul>
<li><strong>UI framework:</strong> to be able to quickly switch between recommendation types in the frontend, a unified framework for all the platforms.</li>
<li><strong>[Micro]-Services:</strong> different services for different recommendations with a unified ranker component on top of them. Allows to quickly plug-and-play different algorithms.</li>
<li><strong>Unified tracking:</strong> so often overlooked but such an important mention.</li>
</ul>
</section>
</section>
<section id="efficiency" class="level2">
<h2 class="anchored" data-anchor-id="efficiency">Efficiency</h2>
<section id="nvidia" class="level3">
<h3 class="anchored" data-anchor-id="nvidia">NVIDIA</h3>
<p>Following-up on the <a href="https://www.eliasnema.com/data-meets-product/2020/09/22/newsletter-video.html">last week’s video topic</a>. Building an ML application on top of a video stream is not something easy and requires expertise in multiple domains. So <a href="https://developer.nvidia.com/blog/deploying-models-from-tensorflow-model-zoo-using-deepstream-and-triton-inference-server/">NVIDIA wants to help</a> you make deployment of such kind of applications easier. This also falls into the <strong>“democratize”</strong> suit. Here is an excerpt from <a href="https://developer.nvidia.com/blog/implementing-a-real-time-ai-based-face-mask-detector-application-for-covid-19/">their other article</a>, explaining how to build a real-time face-mask detector application:</p>
<blockquote class="blockquote">
<p>To use TLT [NVIDIA’s transfer learning tool] and DeepStream you do not necessarily have to know all the concepts in depth, such as transfer learning, pruning, quantization, and so on. These simple toolkits abstract away the complexities, allowing you to focus on your application.</p>
</blockquote>
<p>So the modern-day workflow for the AI video app can look like this:</p>
<pre class="text"><code>Download a pretrained model
            |
            |--&gt; Get data for your use case
                        |
                        |--&gt; Retrain (Transfer learning) &amp; Prune
                                    |
                                    |--&gt; Export model and use with DeepStream library</code></pre>
<p>I want to point the <code>Prune</code> part, which is becoming more and more relevant for the production systems. And there are many ways to do it, some I’ve covered in a <a href="https://www.eliasnema.com/data-meets-product/2020/07/20/newsletter-gpt.html">previous post</a>, but you can also check <a href="https://developer.nvidia.com/blog/transfer-learning-toolkit-pruning-intelligent-video-analytics/">NVIDIA’s blog post</a>.</p>
<p>Why is it important? For example, in the face-mask detection example running on a Jetson Nano after pruning the mean average precision has <strong>dropped from 86.12 to 85.5%</strong>, while frames per second <strong>increased more than 3 times</strong> — from 6.5 to 21.25.</p>
<p>This doesn’t even feel like a trade-off!</p>
<p>Here is also a free course from them to get started with video analytics: <a href="https://courses.nvidia.com/courses/course-v1:DLI+C-IV-02+V1/about">Getting Started with DeepStream for Video Analytics on Jetson Nano</a>.</p>
</section>
<section id="tflites-nlp" class="level3">
<h3 class="anchored" data-anchor-id="tflites-nlp">TFLITE’s NLP</h3>
<p>And more on the topic of efficiency. Google has <a href="https://blog.tensorflow.org/2020/09/whats-new-in-tensorflow-lite-for-nlp.html">added many things around NLP into the TF Lite</a>.</p>
<p>So that it’s easier to do things like that in your browser: <img src="https://www.eliasnema.com/posts/newsletter/2020-09-29-bert-browser.png" class="img-fluid" alt="bert-browser"></p>
<p><em>Image from <a href="https://blog.tensorflow.org/2020/03/exploring-helpful-uses-for-bert-in-your-browser-tensorflow-js.html">this blog post</a> about the in-browser BERT.</em></p>
<p>And these capabilities are also unlocked by the pruning and quantization. Just take a look at how much more efficient the model becomes after losing only a fraction in accuracy: <img src="https://www.eliasnema.com/posts/newsletter/2020-09-29-bert-lite.png" class="img-fluid" alt="bert-lite"></p>
</section>
</section>
<section id="pixar" class="level2">
<h2 class="anchored" data-anchor-id="pixar">Pixar</h2>
<p>And after some philosophy let’s end when it’s best. If you always wondered how would you look like a Pixar character, now you have a chance <a href="https://toonify.justinpinkney.com/">to see that</a>. As well as an informative <a href="https://www.youtube.com/watch?v=KZ7BnJb30Cc">conversation with its creator</a>.</p>
<blockquote class="twitter-tweet blockquote">
<p lang="en" dir="ltr">
Blending humans and cartoons using <a href="https://twitter.com/Buntworthy?ref_src=twsrc%5Etfw"><span class="citation" data-cites="Buntworthy">@Buntworthy</span></a>'s Google Colab notebook. Thank you for that, it's awesome. Here is a YouTube version of this video: <a href="https://t.co/7bUd7nXaX3">https://t.co/7bUd7nXaX3</a> <a href="https://t.co/iG09lpEAXX">pic.twitter.com/iG09lpEAXX</a>
</p>
— Doron Adler (<span class="citation" data-cites="Norod78">@Norod78</span>) <a href="https://twitter.com/Norod78/status/1297513475258953728?ref_src=twsrc%5Etfw">August 23, 2020</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>


</section>

 ]]></description>
  <category>data-meets-product</category>
  <guid>https://www.eliasnema.com/posts/newsletter/2020-09-28-newsletter-democracy-efficiency.html</guid>
  <pubDate>Mon, 28 Sep 2020 23:00:00 GMT</pubDate>
</item>
<item>
  <title>📹 Tensorflow.js, AI in Video and Analytics</title>
  <dc:creator>Elias Nema</dc:creator>
  <link>https://www.eliasnema.com/posts/newsletter/2020-09-22-newsletter-video.html</link>
  <description><![CDATA[ 





<section id="ml-in-the-browser" class="level2">
<h2 class="anchored" data-anchor-id="ml-in-the-browser">ML in the Browser</h2>
<p>What can you do with ML in a modern browser? A showcase from the TensorFlow.js community. My personal favorites were:</p>
<ul>
<li><p><a href="https://demos.touch-less.dev/">Touch-less interface for your hand</a>. It takes some time to get used to it and there is still some polishing to be made. However, after a bit of practice, it becomes kind of fun.</p></li>
<li><p><a href="https://enjoyingthe.show/#explainer">Analyze emotions of your audience in real-time</a>, so that your amazing jokes no longer end in awkwardly muted silence.</p></li>
</ul>
<iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/fZ1rzawCPD4?controls=0" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
</iframe>
</section>
<section id="ai-in-video" class="level2">
<h2 class="anchored" data-anchor-id="ai-in-video">AI in Video</h2>
<ul>
<li><p><a href="https://www.synthesia.io/">Synthesia</a> — a new service to generate video-content:</p>
<ul>
<li>Chose from predefined narrators</li>
<li>Type the script</li>
<li>It’ll create a video of the person presenting your text in some minutes</li>
</ul></li>
<li><p><a href="https://github.com/tryolabs/norfair">Norfair</a> — an open-source library from the <a href="https://tryolabs.com/blog/2020/09/10/releasing-norfair-an-open-source-library-for-object-tracking/">Tyro-labs</a> for the object tracking (cars, pedestrians, poses).</p></li>
<li><p>And if those are not cool enough for you, how about generating realistic tennis matches with real players. <a href="https://cs.stanford.edu/~haotianz/research/vid2player/">Vid2Player</a> does exactly that. Wanted to change the grand-slam history or play Federer against Federer? Well, now you can do that:</p></li>
</ul>
<iframe width="560" height="315" src="https://www.youtube.com/embed/GnZUIuOzgQc" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
</iframe>
<ul>
<li>And since both AI and Video require quite some compute resources and following the horrible launch of 30x cards from NVIDIA, <a href="http://timdettmers.com/2020/09/07/which-gpu-for-deep-learning/">here is a guide</a> on how to chose the one that suits you best while waiting for the cards’ availability.</li>
</ul>
</section>
<section id="analytics" class="level2">
<h2 class="anchored" data-anchor-id="analytics">Analytics</h2>
<p>Relaunch of the analytics blog at Netflix has brought two recent articles. <a href="https://netflixtechblog.com/analytics-at-netflix-who-we-are-and-what-we-do-7d9c08fe6965?source=rss----2615bd06b42e---4">The first one</a> is about the broader role of an analyst. I think this diagram is quite cool and shows the depth of what’s analytics in data organizations.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://www.eliasnema.com/posts/newsletter/2020-09-22-analytics-netflix.png" class="img-fluid figure-img"></p>
<figcaption>analytics-netflix</figcaption>
</figure>
</div>
<p>In <a href="https://netflixtechblog.com/how-our-paths-brought-us-to-data-and-netflix-4eced44a6872?source=rss----2615bd06b42e---4">the other article from them</a>, there is an interview with a couple of data folks. In the spirit of:</p>
<blockquote class="blockquote">
<p>Everyone wants to build fancy models or tools, but fewer are willing to do the foundational things like cleaning the data and writing the documentation.</p>
</blockquote>
<p>Enough of Netflix. Lastly, an interesting (though quite wordy) <a href="https://counting.substack.com/p/data-cleaning-is-analysis-not-grunt">take on data cleansing</a> and why it’s not as simple as it’s often presented. I enjoy a lot the attitude from the author:</p>
<blockquote class="blockquote">
<p>TL;DR: Cleaning data is considered by some people [citation needed] to be menial work that’s somehow “beneath” the sexy “real” data science work. I call BS.</p>
</blockquote>


</section>

 ]]></description>
  <category>data-meets-product</category>
  <guid>https://www.eliasnema.com/posts/newsletter/2020-09-22-newsletter-video.html</guid>
  <pubDate>Mon, 21 Sep 2020 23:00:00 GMT</pubDate>
</item>
<item>
  <title>🔮 State of Recommendations</title>
  <dc:creator>Elias Nema</dc:creator>
  <link>https://www.eliasnema.com/posts/state-of-reco/state-of-reco.html</link>
  <description><![CDATA[ 





<section id="overview" class="level2">
<h2 class="anchored" data-anchor-id="overview">Overview</h2>
<p>This is a lengthy piece covering 6 articles, 4 papers and demonstrating trends happening in the field of <strong>applied recommender systems</strong>. Cases below will be structured as follows:</p>
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<pre class="mermaid mermaid-js">flowchart LR
  A(Overview) --&gt; B(Data)
  B --&gt; C(Model)
  C --&gt; D(Validation)
  D --&gt; E(Production)
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
<p>I prefer not to focus on the reported results because they are usually relative to the previous baselines and easily interpreted outside the context.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://www.eliasnema.com/posts/state-of-reco/reco.png" alt="Fig 1. Summary of Trends" width="500" class="figure-img"></p>
<figcaption>Fig 1. Summary of Trends</figcaption>
</figure>
</div>
<blockquote class="blockquote">
<ul>
<li>Starting back in the days with a timeless classic of recsys — matrix factorization, it’s now hard to find a system without some kind of <strong>neural nets, embedding spaces or sequential models.</strong></li>
<li>Serving has also moved to more <strong>real-time</strong> architectures and dynamic <strong>re-rankers.</strong> Not to mention that generally, the focus now is <strong>much more on the system as a whole</strong>, rather than just a modeling part.</li>
<li>Moving from relying mostly on explicit ratings to incorporating different <strong>implicit</strong> signals and giving them weights. Hence, also the <strong>regression→classification</strong> shift.</li>
<li>On the <strong>item side</strong> pretty much every one converged to building embeddings to optimize for the product similarity.</li>
<li>On the <strong>user side,</strong> however, representations vary depending on the use case and business model.</li>
</ul>
</blockquote>
<p>But the truth is in details, so let’s dive in.</p>
</section>
<section id="linkedin" class="level2">
<h2 class="anchored" data-anchor-id="linkedin"><img src="https://www.eliasnema.com/posts/state-of-reco/linkedin.png" width="35"> LinkedIn</h2>
<section id="linkedin-learning" class="level3">
<h3 class="anchored" data-anchor-id="linkedin-learning">LinkedIn Learning</h3>
<p>We start with the LinkedIn Learning use case and their two-part article (<a href="https://engineering.linkedin.com/blog/2020/course-recommendations-ai-part-one">one</a>, <a href="https://engineering.linkedin.com/blog/2020/course-recommendations-ai-part-two">two</a>). The main goal for them is to <em>“surface the most relevant and personalized course recommendations”</em>.</p>
<p>At LinkedIn, two main models are powering the offline (precalculated for each user daily) recommendations — <strong>neural collaborative filtering</strong> and <strong>“response prediction” model.</strong></p>
<section id="linkedin-learning-collaborative-filtering-neural" class="level4">
<h4 class="anchored" data-anchor-id="linkedin-learning-collaborative-filtering-neural">LinkedIn Learning: Collaborative Filtering (Neural)</h4>
<p>Pros/cons of CF are well-known and LinkedIn didn’t escape them. Here is their recap:</p>
<ul>
<li>works better for core learners (members who are already active on the LinkedIn Learning platform)</li>
<li>focuses on recent interactions <em>(not a very common one, probably a property of their implementation)</em></li>
<li>diversified recommendations, no domain knowledge needed, however, cold start problems</li>
</ul>
<blockquote class="blockquote">
<p>I think recency and diversity are the most interesting points here.</p>
<ul>
<li><strong>Recency:</strong> generally, CF doesn’t give preference for the recent items unless implemented with some kind of time decay or position-aware component in the model.</li>
<li><strong>Diversity:</strong> in e-commerce, CF often <strong>reduces</strong> diversity because of the rich-get-richer effect. And here, probably, due to the fact that the course catalog is not that big and that every person can take any course, it actually increases it.</li>
</ul>
</blockquote>
<p><strong>🛢Data:</strong> course watch history data with a watch-time threshold (if a learner only watches the first three seconds of a course, it’s not included).</p>
<p><strong>🚗Model:</strong></p>
<ul>
<li>Computing learner and course embeddings in parallel. This is also known as a <em>two-tower architecture.</em></li>
<li>Log loss is used as an optimization function.</li>
<li>The modeling objective is to predict course watches using the past watches.</li>
<li>4 negative samples are taken for each positive one.</li>
<li>Holding the last interaction for each user for a test set — a <strong>leave-one-out</strong> approach.</li>
</ul>
<blockquote class="blockquote">
<p>Two-tower architecture consists of two networks with fully connected layers in each becoming narrower with each consecutive layer.</p>
</blockquote>
<p><strong>🔁Validation:</strong> A random sample of 100 items that user didn’t interact with is taken and the one hidden item (user’s last action) is ranked against these 100. Performance is judged by <strong>hit ratio and NDCG</strong> at 10.</p>
<blockquote class="blockquote">
<p>Interesting that input to the learner part is <strong>user/course co-occurrence matrix</strong>, while input to the course part is <strong>course/course similarity</strong> matrix.</p>
</blockquote>
<p><strong>🎬Production:</strong> Generating top K courses for each user based on the similarity between embeddings. Calculating offline and storing in a key-value storage.</p>
</section>
<section id="linkedin-learning-response-prediction-model" class="level4">
<h4 class="anchored" data-anchor-id="linkedin-learning-response-prediction-model">LinkedIn Learning: Response Prediction Model</h4>
<p>Another offline model to compliment CF is so-called “Response Prediction”. It takes into account user and course metadata as well as user’s actions.</p>
<blockquote class="blockquote">
<p>This algorithm typically performs better than CF for members with no/little previous engagement on LinkedIn Learning, as well as for new courses with few prior interactions.</p>
</blockquote>
<p><strong>🛢Data</strong>:</p>
<ul>
<li>User profile features (skills, industry, etc.)</li>
<li>Course metadata (difficulty, category, skills)</li>
<li>Historical explicit engagement (clicks, bookmarks, etc.) with the course watch time as an importance weight given to each click instance.</li>
</ul>
<blockquote class="blockquote">
<p>As a result, this importance weight helps to promote courses with higher watch times and creates a model that can optimize for course watches, not just clicks.</p>
</blockquote>
<p><strong>🚗Model</strong>: a fancy named “Generalized Linear Mixture Model (GLMix)” is used here. In reality, it’s quite a simple (though hard computationally, <a href="https://www.kdd.org/kdd2016/papers/files/adf0562-zhangA.pdf">check the paper</a>) approach to express user’s probability to click via a sum of the three components: a global model, per-learner model, and per-course model.</p>
<blockquote class="blockquote">
<p>We are currently working on a model ensemble that can perform personalized blending of Response Prediction and Neural CF models to improve the overall performance on the final recommendation task. Secondly, we also plan to adopt Attention Models into our Neural CF framework for learner profiling, i.e., assigning attention weights to a learner’s course watch history to capture long term and short term interests in a more effective manner.</p>
</blockquote>
<p><strong>🔁Validation:</strong> AUC for offline validation as well as click/apply rates for the online experiments.</p>
<p><strong>🎬Production:</strong> offline two-stage ranking strategy.</p>
<ol type="1">
<li>storing courses and their features in Lucene, after, using features of users to generate 1000 candidates for each</li>
<li>ranking candidates using full GLMix model</li>
</ol>
</section>
</section>
<section id="linkedin-jobs" class="level3">
<h3 class="anchored" data-anchor-id="linkedin-jobs">LinkedIn Jobs</h3>
<p>In their <a href="https://engineering.linkedin.com/blog/2020/quality-matches-via-personalized-ai">next article,</a> LinkedIn shared some insights on their jobs recommendations <strong>(which can potentially be useful for any job-seeker).</strong> For example:</p>
<blockquote class="blockquote">
<p>Our analysis demonstrated that the majority of job applicants <strong>apply to at least 5 jobs</strong>, while the majority of <strong>job postings receive at least 10 applicants</strong>. This proves to result in enough data to train the personalization models.</p>
</blockquote>
<p><strong>Goal</strong>: to predict the probability of a positive recruiter action, conditional on a given member applying to a given job.</p>
<p><strong>🛢Data</strong>: how to identify if a signal is negative (have someone not replied because of lack of interest or because he is processing other candidates)? &gt; We make the negatives conclusive if no engagement is seen after 14 days. However, if a recruiter responds to other applications submitted later, we may infer the negative label earlier.</p>
<p>Now you know when to stop waiting for the recruiter’s response ⏳.</p>
<p><strong>🚗Model</strong>: here, the same model from the above (GLMix).</p>
<div class="line-block">logit(P(positive response | member, job)) =<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>F_global(X_member, X_job) + F_member(X_job) + F_job(X_member)</code></div>
<blockquote class="blockquote">
<p>We used linear models for fm and fj, but one <strong>can use any model in the above formulation as long as the produced scores are calibrated to output log-odds</strong> (for example, a neural net). Usually, linear models are sufficient as per-member and per-job components, as individual members and individual jobs <strong>do not have enough interactions</strong> to train more complex non-linear models.</p>
</blockquote>
<p><strong>🔁Validation</strong>: AUC and NDCG are used.</p>
<p><strong>🎬Production</strong>:</p>
<ul>
<li>user/job models are retrained daily, with automated quality checks in place</li>
<li>global model his updated once every few weeks</li>
<li>initializing weights with existing values to reduce the training time</li>
</ul>
<p>You can see that features of your profile play a very important role when you are searching for a job, so if you are looking for something specific, <strong>make sure to include the relevant signals into your profile at least a couple of days before.</strong></p>
</section>
</section>
<section id="avito" class="level2">
<h2 class="anchored" data-anchor-id="avito"><img src="https://www.eliasnema.com/posts/state-of-reco/avito.png" width="35"> Avito</h2>
<p>A very <a href="https://habr.com/ru/company/avito/blog/491942/">important and thoughtful article</a> (in Russian) from our friends at Avito. And their approach takes a bit different direction. What if instead of learning personalized recommendations we’d try to optimize for the <strong>item similarity</strong>?</p>
<p><strong>🛢Data:</strong> pairs of “similar” items.</p>
<p>How to define similars? Items that were “contacted” (the best proxy for the transaction in classifieds) by a user with a time threshold between actions (8h for Avito). This gives 1s as a label. How to get 0s? Negative sampling from the items that were active at the platform during the time of contact but were not selected by the user.</p>
<blockquote class="blockquote">
<p>Random sampling with a probability of an item being selected equals to a <strong>square root of a number of contacts that this item got</strong> (how popular the item was).</p>
</blockquote>
<p><strong>🚗Model:</strong> item features are fed into the embedding layers with a dropout and 2 linear layers on top. <strong>Item IDs are not included</strong> into item features to allow for model generalization.</p>
<blockquote class="blockquote">
<p>The last layer is tanh to transform the output into the [-1, 1] range and <strong>multiply by 128</strong> later to fit into the INT8 to save memory in serving.</p>
</blockquote>
<p>Calculating scores for the positive sample and 4000 (the more — the better, constraint of the GPU memory) negative samples for each pair. Taking highest scores from the negatives (top 100 wrongly predicted items) and computing the log-loss.</p>
<blockquote class="blockquote">
<p>Learning only from the top 100 wrong predictions allows to <strong>save on training time without loosing the accuracy</strong>.</p>
</blockquote>
<p><strong>🔁Validation:</strong> precision at 8 is calculated on a test set. Time-based split, with <strong>omitting 6 months</strong> of data between training and validation. This is done to see how model will behave after 6 months of not training.</p>
<p><strong>🎬Production:</strong> The model is re-trained once per 6 months. This works fine because item IDs are not included into training so new items can be embedded into the space just by their features. So new items get’s represented in a space as soon as they are posted. Embeddings are stored in Sphinx search engine, which allows quite a fast vector search (p99 is under 200ms with 200k rpm, sharded by category).</p>
<p>Recommendations are used on both the item page (item-to-item) and the homefeed (user-to-item), with user-to-item generated from the similar items to the ones that user has seen recently.</p>
</section>
<section id="pinterest" class="level2">
<h2 class="anchored" data-anchor-id="pinterest"><img src="https://www.eliasnema.com/posts/state-of-reco/pinterest.png" width="35"> Pinterest</h2>
<p>And now — Pinterest. Another very thoughtful and pragmatic <a href="https://medium.com/pinterest-engineering/pinnersage-multi-modal-user-embedding-framework-for-recommendations-at-pinterest-bfd116b49475">piece from them</a>.</p>
<p>Here as well, the general idea is to embed users/items into some space. However, having a single vector for user works bad — no matter how good the network is it won’t be able to represent all the clusters of user’s interests. Another approach (the same as Avito takes above) is to represent <strong>a user via embeddings of items</strong> that he is interested in. But averaging of embeddings works bad for the longer-term user interests (e.g.&nbsp;<a href="https://miro.medium.com/max/1400/0*KB50oLyVlnzoGuen">paintings and shoes average to a salad</a>). The solution?</p>
<p>Run <strong>clustering</strong> on the user’s actions and take <strong>medoids</strong> (like centroids, but should be an existing item) from the most important clusters. Find similar items to those medoids.</p>
<p><strong>🛢Data:</strong> users’ action pins from the last 90 days.</p>
<p><strong>🚗Model:</strong> the main model is quite a simple <a href="https://en.wikipedia.org/wiki/Ward%27s_method">Ward clustering</a> with the goal to produce different amount of clusters depending on a variety of items in the user’s history. A time decay average is used to assign importance to clusters.</p>
<p><strong>🔁Validation:</strong> a very thorough approach to the evaluation process, highly recommend to check out more in the <a href="https://arxiv.org/pdf/2007.03634.pdf">paper</a>.</p>
<ul>
<li>Cluster user’s actions and rank clusters by importance.</li>
<li>Get 400 closest items to the medoids of the most important clusters.</li>
<li>Calculate <strong>relevance:</strong> the proportion of observed action pins that have high cosine similarity (≥0.8) with any recommended pin.</li>
<li>And <strong>recall:</strong> the proportion of action pins that are found in the recommendation set.</li>
<li>Test batches are calculated in the chronological order, day by day, simulating the production setup.</li>
</ul>
<p><strong>🎬Production</strong>:</p>
<ul>
<li>Using HNSW for the approximate nearest neighbor search</li>
<li>Filtering out near-duplicates and lower quality pins</li>
<li>Using medoids allows saving on caching (no need to compute aNN all the time)</li>
</ul>
<p>Served using a classical <a href="https://en.wikipedia.org/wiki/Lambda_architecture">lambda architecture</a>:</p>
<blockquote class="blockquote">
<ol type="1">
<li>Daily Batch Inference: PinnerSage is run daily over the <strong>last 90 day actions</strong> of a user on a MapReduce cluster. The output of the daily inference job (list of medoids and their importance) are served online in key-value store.</li>
<li>Lightweight Online Inference: We collect the <strong>most recent 20 actions</strong> of each user on the latest day (after the last update to the entry in the key-value store) for online inference. PinnerSage uses a real-time event-based streaming service to consume action events and update the clusters initiated from the key-value store.</li>
</ol>
<p><strong>In practice, the system optimization plays a critical role in enabling the productionization of PinnerSage.</strong></p>
</blockquote>
</section>
<section id="coveo-coveo" class="level2">
<h2 class="anchored" data-anchor-id="coveo-coveo"><img src="https://www.eliasnema.com/posts/state-of-reco/coveo.png" width="35" alt="coveo"> Coveo</h2>
<p>Ok, item embeddings are great. But how about transfer learning for them? Wait, what? The thing is that many companies are actually multi-brand groups having more than one website.</p>
<p>Training embeddings for similar products in different shops will produce spaces which are not comparable. Is there a way to mitigate this? You bet there is.</p>
<p><strong>🛢Data:</strong> the best part is that you don’t need tons of data. All you need is data on how users interacted with products within sessions to build product spaces. After that, product features will come handy (text attributes, prices, images, etc.) to align spaces. Having <strong>cross-shop data</strong> is valuable later but not strictly necessary.</p>
<p><strong>🚗Model:</strong> product embeddings are trained using CBOW with negative sampling, by swapping the concept of words in a sentence with products in a browsing session. This is not the fanciest architecture for item embeddings — check the Avito implementation above for a more sophisticated approach.</p>
<p>More interestingly though is a task to <strong>align product spaces</strong>. It’s different from aligning spaces for languages, mainly, because languanes are guaranteed to have similiar concepts, while for some products it’s not necesseraly true. Coveo has tried different models, but the general approach is:</p>
<ol type="1">
<li>Start with some unsupervised approach, such as pairing by item features, images, etc. This helps finding the initial mapping function.</li>
<li>Later, adjust the space alignment by learning from user interactions with the items in different spaces.</li>
</ol>
<p><strong>🔁Validation:</strong> for the product embeddings model evaluation is done using the leave-one-out approach and by predicting the Nth interactions from the 0..N-1 items: embeddings are averaged for 0..N-1 items and the nearest neighbor search is done to predict the Nth item. NDCG@10 is used on the search result.</p>
<blockquote class="blockquote">
<p>Worth noting that this approach works for the short-lived sessions or specialized shops, while for sessions with multiple intents averaging might produce really weird results (see the Pinterest case above).</p>
</blockquote>
<p><strong>🎬Production</strong>: they run 2 experiments. In both, the idea was to use an intent from one shop and aligned embeddings to</p>
<ul>
<li>predict the user’s next action</li>
<li>predict the best query in the search autocomplete</li>
</ul>
<p>Both experiments have proven the potential behind the approach and I’ll be paying a close attention to the area of transfer learning for product spaces in the future.</p>
<hr>
<p><br> References:</p>
<ol type="1">
<li><a href="https://engineering.linkedin.com/blog/2020/course-recommendations-ai-part-one">LinkedIn’s Learning Recommendations Part 1</a></li>
<li><a href="https://engineering.linkedin.com/blog/2020/course-recommendations-ai-part-two">LinkedIn’s Learning Recommendations Part 2</a></li>
<li><a href="https://arxiv.org/pdf/1708.05031.pdf">LinkedIn’s Neural Collaborative Filtering</a></li>
<li><a href="https://www.kdd.org/kdd2016/papers/files/adf0562-zhangA.pdf">LinkedIn’s Generalized Linear Mixed Models</a></li>
<li><a href="https://engineering.linkedin.com/blog/2020/quality-matches-via-personalized-ai">LinkedIn Jobs’ article</a></li>
<li>Avito’s <a href="https://habr.com/ru/company/avito/blog/491942/">article</a></li>
<li>Pinterest’s <a href="https://medium.com/pinterest-engineering/pinnersage-multi-modal-user-embedding-framework-for-recommendations-at-pinterest-bfd116b49475">article</a></li>
<li>Pinterest’s <a href="https://arxiv.org/pdf/2007.03634.pdf">paper</a></li>
<li>Coveo’s blog posts: <a href="https://blog.coveo.com/multi-brand-personalization-in-ecommerce/">one</a>, <a href="https://blog.coveo.com/clothes-in-space-real-time-personalization-in-less-than-100-lines-of-code/">two</a></li>
<li>Coveo’s <a href="https://blog.coveo.com/multi-brand-personalization-in-ecommerce/">paper</a></li>
<li><a href="https://developers.google.com/machine-learning/recommendation/dnn/softmax#can-you-use-item-features">Intro to recommendations</a> by Google</li>
</ol>


</section>

 ]]></description>
  <category>recommendations</category>
  <guid>https://www.eliasnema.com/posts/state-of-reco/state-of-reco.html</guid>
  <pubDate>Fri, 04 Sep 2020 23:00:00 GMT</pubDate>
</item>
<item>
  <title>🛢 Data</title>
  <dc:creator>Elias Nema</dc:creator>
  <link>https://www.eliasnema.com/posts/newsletter/2020-08-03-newsletter-data.html</link>
  <description><![CDATA[ 





<section id="metadata-medical-data-and-tf.data" class="level2">
<h2 class="anchored" data-anchor-id="metadata-medical-data-and-tf.data">Metadata, Medical Data and TF.Data</h2>
<p>Announcements in the metadata management from Shopify and Stripe. What it takes to build a startup in the field of medical AI, and how much time you’ll spend gathering data for it. TensorFlow’s latest release was mostly about its data API.</p>
</section>
<section id="ai-in-medicine" class="level2">
<h2 class="anchored" data-anchor-id="ai-in-medicine">🩺 AI in Medicine</h2>
<p>Highly recommend the <a href="https://www.datafuturology.com/podcast/2020/7/14/127-reinventing-prostate-cancer-testing-with-ai-from-development-to-regulation-to-production-with-elliot-smith-ceo-amp-founder">Data Futurology podcast</a> about what it takes to build an AI company in the medical sphere. Many interesting things, but what it takes to build real-world datasets in the wild is always worth hearing:</p>
<ul>
<li>“There is a lot of differences in medical data — if you did MRIs in two different centers, you cannot just take data from both of them and use it.”</li>
<li>“Another under-appreciated aspect of building a lot of real-world AI applications, where, unlike kaggle, nobody’s got a 100 thousand in a nicely organized folder… Sometimes only having data for 10 patients at a time, scans coming on CDs, 1 at a time.”</li>
</ul>
<blockquote class="blockquote">
<p>“As much as our system involves AI and image processing there is probably just as much if not more work in around data standardization, data cleanliness and manual intervention into data.”</p>
</blockquote>
<ul>
<li>2.5 years (from 5!) were spent on building a political relationship (with doctors), gathering data piece by piece, later building integrations with existing systems.</li>
<li>“The best results were coming from building a relationship with individual doctors.”</li>
</ul>
<p>To sum it up, I think that data gathering relationship building is <strong>the new sales</strong>. Building a company that relies on data, you are as good as the number of data providers you’ve built a relationship with.</p>
</section>
<section id="metadata" class="level2">
<h2 class="anchored" data-anchor-id="metadata">📼 Metadata</h2>
<p>Two of the big players have released something about their metadata solutions. Many of the big players already have established solutions for a couple of years, with Shopify being the latest company to build their own.</p>
<section id="shopifys-artifact" class="level3">
<h3 class="anchored" data-anchor-id="shopifys-artifact"><a href="https://engineering.shopify.com/blogs/engineering/solving-data-discovery-challenges-shopify">Shopify’s Artifact</a></h3>
<ul>
<li>Their implementation uses Elasticseach and a graph database to provide search and data lineage respectively. GraphQL’s Apollo as an API layer. Quite a standard stack. Similar to e.g.&nbsp;<a href="https://lyft.github.io/amundsen/architecture/">this one</a>.</li>
<li>Other than that, from the screenshots it looks like it does what it should and looks very much like similar systems. However, a quote from the article explaining why it’s generally hard to reuse existing solutions:</li>
</ul>
<blockquote class="blockquote">
<p>Every organization’s data stack is different. While some upstream processes can be standardized and cataloged appropriately, the business context of downstream processes creates a wide distribution of requirements that are near impossible to satisfy with a one-size-fits-all solution.</p>
</blockquote>
</section>
<section id="stripe-and-privacy" class="level3">
<h3 class="anchored" data-anchor-id="stripe-and-privacy">Stripe and Privacy</h3>
<p><a href="https://developer.squareup.com/blog/using-amundsen-to-support-user-privacy-via-metadata-collection-at-square/">Stripe is using</a> their <a href="https://lyft.github.io/amundsen/">Amundsen</a> metadata tool to increase focus on consumer privacy and better comply with GDPR and CCPA.</p>
</section>
<section id="other-companies" class="level3">
<h3 class="anchored" data-anchor-id="other-companies">Other companies</h3>
<p>A collection of <a href="https://github.com/eugeneyan/applied-ml">data discovery articles</a>.</p>
</section>
</section>
<section id="tensorflow-2.3" class="level2">
<h2 class="anchored" data-anchor-id="tensorflow-2.3">🖇 Tensorflow 2.3</h2>
<p>Ironically the <a href="https://blog.tensorflow.org/2020/07/whats-new-in-tensorflow-2-3.html">latest TensorFlow release</a> is also about data. Two of the main additions to the help make preprocessing smoother. I think preprocessing may very well be the most overlooked step and improving it is hugely beneficial.</p>
<ul>
<li><strong>td.data.snapshot</strong>: allows you to run the preprocessing pipeline once, save the output and play with parameter optimization on top of that. Read more details in the <a href="https://github.com/tensorflow/community/blob/master/rfcs/20200107-tf-data-snapshot.md">RFC</a>.</li>
<li><strong><a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing?version=nightly">Preprocessing layer API</a></strong>: package preprocessing logic inside a model for easier deployment.</li>
</ul>
<hr>
<p><br></p>
<p>To finish on a positive note, here is an awesome 3 minutes <a href="https://www.youtube.com/watch?v=kpiY_LemaTc">Lex Fridman’s video</a> estimating costs for GPT to equal a human brain:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://www.eliasnema.com/posts/newsletter/2020-08-03.png" class="img-fluid figure-img"></p>
<figcaption>gpt costs</figcaption>
</figure>
</div>


</section>

 ]]></description>
  <category>data-meets-product</category>
  <guid>https://www.eliasnema.com/posts/newsletter/2020-08-03-newsletter-data.html</guid>
  <pubDate>Sun, 02 Aug 2020 23:00:00 GMT</pubDate>
</item>
<item>
  <title>🔎 Paid Search</title>
  <dc:creator>Elias Nema</dc:creator>
  <link>https://www.eliasnema.com/posts/newsletter/2020-07-28-newsletter-search.html</link>
  <description><![CDATA[ 





<p>This week I ended up reading a couple of recent articles around the topic of search. Not groundbreaking paper’s style. Rather down-to-earth field implementations. Below, I’ll go through the paid search challenges in two major online platforms. And then to the emerging role of a Relevance Engineer.</p>
<section id="pinterest" class="level2">
<h2 class="anchored" data-anchor-id="pinterest"><img src="https://www.eliasnema.com/posts/newsletter/pinterest.png" width="35"> Pinterest</h2>
<p><a href="https://medium.com/pinterest-engineering/driving-shopping-upsells-from-pinterest-search-d06329255402">Shopping upsells on Pinterest</a>. An interesting story. Let me decompose it to the common steps seen across data projects.</p>
<p>A simple problem to solve — introduce ads into the search results. They call it “shopping upsells“. Imagine you need to build a shopping upsell model.</p>
<section id="step-1.-get-data." class="level3">
<h3 class="anchored" data-anchor-id="step-1.-get-data.">Step 1. Get Data.</h3>
<p>Where to get the data for a feature that doesn’t yet exist on a platform?</p>
<ul>
<li>One approach: randomly display a portion of upsells for all queries. However, this way the product quality is mixed with the user intent for shopping — not clear if the user doesn’t want to buy in general or doesn’t like this particular ad.</li>
<li>A better approach: <em>embed products in both upsell and organic sections</em>, but hide prices in organic. This way is possible to distill the intent of a user and make data less noisy.</li>
</ul>
</section>
<section id="step-2.-get-model." class="level3">
<h3 class="anchored" data-anchor-id="step-2.-get-model.">Step 2. Get Model.</h3>
<p>You’ve got data, get a model.</p>
<ul>
<li>Use business knowledge to come up with a smart objective. Clicks on products are usually noisy, but a good first start. Much better to assign proper weights to strong signals and smartly combine them. Pinterest uses pins and clicks to partner sites.</li>
<li><a href="https://miro.medium.com/max/300/0*kI9UvZRbnPFM1RJ2">Model architecture</a>:<br>
<code>Query -&gt; Embedding -&gt; Encoder -&gt; Dense -&gt; Log Loss</code></li>
</ul>
<p>New practitioners are often disappointed by seeing simple architectures after all the resnets and RNNs they’ve just studied. But complexity and state-of-the-arts are often wrong fallacies to chase for most of the businesses.</p>
</section>
<section id="step-3a.-get-results." class="level3">
<h3 class="anchored" data-anchor-id="step-3a.-get-results.">Step 3a. Get Results.</h3>
<blockquote class="blockquote">
<p>“After launching the experiment, the model increased more than 2X traffic to the shopping search page without hurting overall search metrics in terms of long clicks or saves. The model also increased more than 2X product impressions and product long clicks through the upsell.“</p>
</blockquote>
</section>
<section id="step-3b.-hack-production." class="level3">
<h3 class="anchored" data-anchor-id="step-3b.-hack-production.">Step 3b. Hack Production.</h3>
<p>Having the results you now need to hack the costs to get the “model economics” right.</p>
<ul>
<li>For example, they are smartly precomputing head queries and filtering out “non-shoppable categories, such as ‘recipe’ or ‘finance’.”</li>
</ul>
<p>My bet is that Pinterest didn’t come up with these optimizations from the beginning. Usually, it’s a loop of 2-3b steps until you get all the components right. This often-overlooked cycle of small adjustments, in this case, allowed to reduce model serving traffic by 70% 🤯</p>
</section>
</section>
<section id="ebay" class="level2">
<h2 class="anchored" data-anchor-id="ebay"><img src="https://www.eliasnema.com/posts/newsletter/ebay.png" width="35"> Ebay</h2>
<p><a href="https://tech.ebayinc.com/product/ebay-makes-promoted-listings-in-search-results-more-relevant-and-dynamic/">Ebay’s article</a> on balancing paid and non-paid content in their search results.</p>
<p>The basic idea is that having fixed paid slots is bad. Both for the:</p>
<ul>
<li><em>head queries</em>, for which there is much more paid content than it’s possible to fit</li>
<li>as well as <em>tail queries</em>, for which there is often not enough high-quality paid content</li>
</ul>
<p>The solution? Get rid of the fixed paid slots and rank the whole search result according to “relevancy“. Here is a more detailed summary:</p>
<blockquote class="twitter-tweet blockquote">
<p lang="en" dir="ltr">
<a href="https://twitter.com/ebaytech?ref_src=twsrc%5Etfw"><span class="citation" data-cites="ebaytech">@ebaytech</span></a> has recently released an article on balancing the paid and non-paid content in their search result page (thread)⁰<a href="https://twitter.com/hashtag/ecommerce?src=hash&amp;ref_src=twsrc%5Etfw">#ecommerce</a> <a href="https://twitter.com/hashtag/Search?src=hash&amp;ref_src=twsrc%5Etfw">#Search</a> <a href="https://twitter.com/hashtag/marketplace?src=hash&amp;ref_src=twsrc%5Etfw">#marketplace</a> ⁰<a href="https://t.co/REualIf6Aq">https://t.co/REualIf6Aq</a>
</p>
— Elias Nema (<span class="citation" data-cites="EliasNema">@EliasNema</span>) <a href="https://twitter.com/EliasNema/status/1286420652539424773?ref_src=twsrc%5Etfw">July 23, 2020</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</section>
<section id="ds-or-ml-re" class="level2">
<h2 class="anchored" data-anchor-id="ds-or-ml-re">🕵️‍♀️ DS or ML? RE!</h2>
<p><a href="https://opensourceconnections.com/blog/2020/07/16/what-is-a-relevance-engineer/">Another interesting take</a> on the career in the data field from one of the most famous search practitioners. A couple of highlights:</p>
<ul>
<li>Who is a relevance engineer: <em>“implements information retrieval algorithms that solve user information needs in real time, at scale“</em></li>
<li>Applied approach: <em>“don’t chase the state of the art unnecessarily, rather they prefer proven techniques for 80% of the problem“, “don’t solve search for Kaggle points or academia, but for real companies and users“</em></li>
<li>How it’s different from ML engineer: both roles are very similar, with relevance engs tending to be more user-centric and focused on IR problems (ML is broader and not necessarily user-facing problems)</li>
</ul>
<p>I think the role will become more popular going forward with many companies realizing the need and value of showing relevant content to users in an ever-shrinking customer attention span.</p>


</section>

 ]]></description>
  <category>data-meets-product</category>
  <guid>https://www.eliasnema.com/posts/newsletter/2020-07-28-newsletter-search.html</guid>
  <pubDate>Mon, 27 Jul 2020 23:00:00 GMT</pubDate>
</item>
<item>
  <title>💥 GPT Excitement and AI Costs</title>
  <dc:creator>Elias Nema</dc:creator>
  <link>https://www.eliasnema.com/posts/newsletter/2020-07-20-newsletter-gpt.html</link>
  <description><![CDATA[ 





<section id="a-week-of-gpt-3-obviously" class="level2">
<h2 class="anchored" data-anchor-id="a-week-of-gpt-3-obviously">A Week of GPT-3, Obviously</h2>
<p>There were so many tweets, articles and general excitement that it became too much even for Sam Altman himself:</p>
<blockquote class="twitter-tweet blockquote">
<p lang="en" dir="ltr">
The GPT-3 hype is way too much. It’s impressive (thanks for the nice compliments!) but it still has serious weaknesses and sometimes makes very silly mistakes. AI is going to change the world, but GPT-3 is just a very early glimpse. We have a lot still to figure out.
</p>
— Sam Altman (<span class="citation" data-cites="sama">@sama</span>) <a href="https://twitter.com/sama/status/1284922296348454913?ref_src=twsrc%5Etfw">July 19, 2020</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
<p>I’m, of course, impressed too. In fact, it was able to produce my most liked tweet 😞 (and same happened to some better-known folks):</p>
<blockquote class="twitter-tweet blockquote" data-conversation="none">
<p lang="en" dir="ltr">
Side note: if this somehow becomes my most viewed tweet ever, I'm going to be sad.
</p>
— Leo Polovets (<span class="citation" data-cites="lpolovets">@lpolovets</span>) <a href="https://twitter.com/lpolovets/status/1284288703200817153?ref_src=twsrc%5Etfw">July 18, 2020</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
<p>There are many great articles covering GPT-3 and its meaning for the future of humanity. You can easily find them, but probably don’t need to, because they pop up everywhere.</p>
<p>Hype aside, it’s a huge model and probably costs a fortune, but the whole product part is done in a very lean way. It’s at the market validation phase, which it has nailed perfectly.</p>
<blockquote class="twitter-tweet blockquote">
<p lang="en" dir="ltr">
In the ultimate lean startup twist it turned out that <a href="https://twitter.com/sama?ref_src=twsrc%5Etfw"><span class="citation" data-cites="sama">@sama</span></a> was manually answering all GPT-3 requests.
</p>
— Andreas Klinger ✌️ (<span class="citation" data-cites="andreasklinger">@andreasklinger</span>) <a href="https://twitter.com/andreasklinger/status/1283981585251880961?ref_src=twsrc%5Etfw">July 17, 2020</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
<p>Probably, the next step would be to optimize costs and <strong>make the economics right</strong> for the rest of the internet. Which brings us to the topic of costs, which becomes as relevant as never for the AI/ML community.</p>
</section>
<section id="costs-in-ai" class="level2">
<h2 class="anchored" data-anchor-id="costs-in-ai">💰Costs in AI</h2>
<ul>
<li>A very interesting conversation on last <a href="https://twimlai.com/twiml-talk-391-the-case-for-hardware-ml-model-co-designwith-diana-marculescu/">week’s TWIML AI podcast</a> about model design optimization for hardware.</li>
<li><a href="https://www.wired.com/story/prepare-artificial-intelligence-produce-less-wizardry/">Another article</a> suggests that despite shaving off 3/4 of errors in logistic optimization prediction with the help of deep learning, a European retailer chose not to use the model because of costs.</li>
</ul>
<p>Until very recently, DL has been driven by the research in big companies. This means almost unlimited resources. It’s great to validate and/or win the market. But with time, you need to get the unit economics right. For training and serving and smaller devices (a smartphone in 2017 was able to run <a href="https://arxiv.org/pdf/1611.05128.pdf">AlexNet only for 1 hour</a>).</p>
<p>Basically there are multiple directions in ML optimizations:</p>
<ul>
<li>Incorporating <a href="https://workshop-edlcv.github.io/slides/901-talk.pdf">power/energy/latency constraints</a> into network architectures search. This <em>“can bring 5‐10x improvement in energy or latency with minimal loss in accuracy or can satisfy real-time constraints for inference”</em>. Basically, by thinking about hardware constraints in advance you can get to almost the same accuracy while saving in the order of magnitudes. An amazing trade-off for most of the businesses.</li>
<li><a href="https://arxiv.org/pdf/1904.02835.pdf">Quantizing neural networks</a>. The idea here is to round model weights to the nearest power of 2, hence allowing using shift and add operations to replace the multiplications. This improves speed and lowers energy consumption. A very smart approach and again, a well-worse trade-off.</li>
<li><a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Chin_Towards_Efficient_Model_Compression_via_Learned_Global_Ranking_CVPR_2020_paper.pdf">Energy-aware pruning of NNs</a>: Often both accuracy and latency are important to the application. This work allows you to quickly iterate over accuracy-vs.-speed trade-off for finding a sweet-spot for a particular application using model compression.</li>
<li><a href="https://arxiv.org/pdf/1806.03198.pdf">Discretizing vectors over a d-dimensional sphere</a>: A super-smart approach where instead of adapting an index to the data, the data is adopted to the index itself. <em>“We learn a neural network that aims at preserving the neighborhood structure in the input space while best covering the output space (uniformly)”</em>.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://www.eliasnema.com/posts/newsletter/to_uniform.png" class="img-fluid figure-img"></p>
<figcaption>to uniform</figcaption>
</figure>
</div>
<p>These are just the directions I’ve seen recently. But the topic is becoming more and more important. If AI aims to turn into a new cloud, the industry needs to figure out the ways to scale the “state-of-the-art“ to the rest of the internet. And it looks like we are finally getting there.</p>


</section>

 ]]></description>
  <category>data-meets-product</category>
  <guid>https://www.eliasnema.com/posts/newsletter/2020-07-20-newsletter-gpt.html</guid>
  <pubDate>Sun, 19 Jul 2020 23:00:00 GMT</pubDate>
</item>
<item>
  <title>📵 No Code and ML Interns</title>
  <dc:creator>Elias Nema</dc:creator>
  <link>https://www.eliasnema.com/posts/newsletter/2020-07-13-newsletter-no-code.html</link>
  <description><![CDATA[ 





<p>Is no code the new oil or the old ETL? TikTok’s recommender and when to use machine learning.</p>
<section id="no-code" class="level2">
<h2 class="anchored" data-anchor-id="no-code">📵 No Code</h2>
<ul>
<li>When AWS launches a service, there is usually good economics behind it. Recently they’ve launched the <a href="https://www.honeycode.aws/">no-code way to build simple mobile apps</a>. It continues the trend started by Notion, Airtable and the likes of building your own productivity tools (of course, AWS is not competing against the Notion but rather against Microsoft Power Apps here). Spreadsheets for the new era.</li>
<li>The Russian design studio <a href="https://www.artlebedev.com/ironov/">was using AI</a> as one of their designers for more than a year. &gt; ”This event marks the moment that the mass automation of creative processes becomes a reality for businesses.”</li>
<li><a href="https://techcrunch.com/2020/07/07/monkeylearn-raises-2-2m-to-build-out-its-no-code-ai-text-analysis-service/">MonkeyLearn raises 2.2M$</a> - not really no-code AI, rather NLP as a service. &gt; “Our vision is to make AI approachable by providing a toolkit for teams to actually use AI in their daily operations,” Garreta said in a release.</li>
<li>Adobe keeps investing in its Sensei AI platform adding seamless no code <a href="https://www.adobe.com/marketing/target.html#demo">personalization and recommenders</a> based on AL and ML, of course. Allows you to automatically A/B test different content variants and more.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://www.eliasnema.com/posts/newsletter/adobe_sensei.png" class="img-fluid figure-img"></p>
<figcaption>Automatically Testing Multiple Onboarding Flows with Adobe Sensei</figcaption>
</figure>
</div>
</section>
<section id="ml-applications" class="level2">
<h2 class="anchored" data-anchor-id="ml-applications">🎛 ML Applications</h2>
<ul>
<li>Facebook will <a href="https://about.fb.com/news/2020/06/prioritizing-original-news-reporting-on-facebook/">prioritize original reporting</a> in the home feed. To identify originals it will look at how often the article is cited as … original.</li>
<li><a href="https://www.producthunt.com/posts/virtual-models-by-rosebud-ai">A nice launch on ProductHunt</a> using GANs to generate models (real ones) for “photoshoots“. Even though the demo is far from perfect. But with the recent e-commerce rise, covid restrictions and all the shopify storefronts, this might be a promising direction. If the model (ML model, in this case) economy can be figured out.</li>
<li>TikTok’s recommenders are apparently really good:</li>
</ul>
<blockquote class="twitter-tweet blockquote">
<p lang="en" dir="ltr">
According to my teenagers, Tiktok has by far the best personalized <a href="https://twitter.com/hashtag/RecSys?src=hash&amp;ref_src=twsrc%5Etfw">#RecSys</a> they have used. Do we know anything about what they are doing?
</p>
— Xavier Amatriain - 🌈💪🏿 (<span class="citation" data-cites="xamat">@xamat</span>) <a href="https://twitter.com/xamat/status/1282467657535467520?ref_src=twsrc%5Etfw">July 13, 2020</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
<p>And my thread about their recent article about how their recommender works:</p>
<blockquote class="twitter-tweet blockquote">
<p lang="en" dir="ltr">
<a href="https://twitter.com/hashtag/Tiktok?src=hash&amp;ref_src=twsrc%5Etfw">#Tiktok</a> has posted an article about their <a href="https://twitter.com/hashtag/recommendations?src=hash&amp;ref_src=twsrc%5Etfw">#recommendations</a> system. There aren't too many details, but some interesting quotes on how they think about the problem space.<br>(1/)<a href="https://t.co/Ou8LfBGjUe">https://t.co/Ou8LfBGjUe</a>
</p>
— Elias Nema (<span class="citation" data-cites="EliasNema">@EliasNema</span>) <a href="https://twitter.com/EliasNema/status/1278803346321801217?ref_src=twsrc%5Etfw">July 2, 2020</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</section>
<section id="why-ml-is-similar-to-interns" class="level2">
<h2 class="anchored" data-anchor-id="why-ml-is-similar-to-interns">👔 Why ML is Similar to Interns</h2>
<p>Finishing with an interesting tweet from Benedict Evans:</p>
<blockquote class="twitter-tweet blockquote">
<p lang="en" dir="ltr">
I quite often describe machine learning as giving you infinite interns. This can be a useful way to look at how ML would affect a product: sometimes having infinite free interns to look at data for you wouldn’t actually solve your problems, and the struggle is something else.
</p>
— Benedict Evans (<span class="citation" data-cites="benedictevans">@benedictevans</span>) <a href="https://twitter.com/benedictevans/status/1280265572782145537?ref_src=twsrc%5Etfw">July 6, 2020</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
<p>I think this is a very good summary for execs who don’t have exposure to the topic. Or for product managers when thinking about prioritization. Very often people tend to forget that ML is about <strong>automation</strong>. Imagine, you have an amazing photo-artist, who can look at the photos you take, pick the best ones, adjust brightness here and there, suggest collages, design a photo book and send to you. This is an awesome service, but also a very expensive one. How about providing it to a billion people? Hence, <strong>Google Photos</strong> cannot compete with the quality of the artist but can provide the service to a billion customers. Same goes for recommendations: a good stylist can probably get you a fashionable outfit, but economics cannot beat the recsys approach (or it can if you are a boutique).</p>
<p>On the other hand, problems where many agents won’t help, such as: shall we launch in the new market, how will customers react to a new feature? These are non-scalable problems. And even if you can and should use data to make a conscious decision there, investing in the ML solution won’t bring benefits.</p>
<p>Too often people confuse the need of <strong>scaling the decision</strong> (good for ML interns) with the need of <strong>taking a good decision from time to time</strong> (ML is of no use here).</p>


</section>

 ]]></description>
  <category>data-meets-product</category>
  <guid>https://www.eliasnema.com/posts/newsletter/2020-07-13-newsletter-no-code.html</guid>
  <pubDate>Sun, 12 Jul 2020 23:00:00 GMT</pubDate>
</item>
<item>
  <title>Hypothesize your way into better products</title>
  <dc:creator>Elias Nema</dc:creator>
  <link>https://www.eliasnema.com/posts/hypothesize/hypothesize.html</link>
  <description><![CDATA[ 





<section id="introduction" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>How do you quickly test ideas in your product? How do you include analytics in your day-to-day development process? How do you embrace failure and stop investing in something that’s not working?</p>

<div class="no-row-height column-margin column-container"><div class="">
<p><img src="https://www.eliasnema.com/posts/hypothesize/doodle.png" width="150"></p>
</div></div><p>When really zoomed out, a common workflow in engineering teams looks like this: <strong>“Idea -&gt; Implementation.”</strong> Work is usually done in short cycles to provide fast feedback loops. But generally, you take an idea, and you implement it.</p>
<p>This comes with two dangerous assumptions:</p>
<ul>
<li>that you already know what to build; and</li>
<li>that everything that you start building needs to be built up to some final readiness.</li>
</ul>
<p>While these might have been fairly safe assumptions in some industries some years ago, it’s hard to find anything further from the truth today. Products are rapidly evolving, becoming more complex, becoming smarter. User expectations are growing at an even faster pace. It’s close to impossible to predict whether a new feature will have an impact just by relying on your gut feeling.</p>
</section>
<section id="hedge-your-risks" class="level2">
<h2 class="anchored" data-anchor-id="hedge-your-risks">Hedge your risks</h2>
<p>I’ve been working in product teams whose solutions rely heavily on data (recommendations, personalization) so that outcomes are not possible to predict (in recommenders, even offline metrics cannot give any guarantees) and iterations take a long time. In such setups, making a wrong assumption and sticking to it till the end brings the worst possible return on investments. There is also a lack of common ground in scope definitions between team members. Often, we just wanted to quickly test the feasibility of an idea, but it turned into a multi-month project that ended up being a disappointment for everyone.</p>
<p>It was clear that we needed a common language among engineering, data and product to save us from making costly bids while maximizing learnings. So we came up with a workflow that allowed us to speak the same language and that specified what the focus should be at each stage of the project.</p>
</section>
<section id="a-common-dictionary" class="level2">
<h2 class="anchored" data-anchor-id="a-common-dictionary">A common dictionary</h2>
<p><img src="https://www.eliasnema.com/posts/hypothesize/flow.png" class="img-fluid"></p>
<p>The flow starts with the <strong>hypothesis</strong>. This is a small but important difference. A hypothesis, by definition, is something that doesn’t have certainty in itself. It can be right; it can be wrong.</p>
<p>Implementation becomes three separate steps:</p>
<ul>
<li><strong>Prototype</strong>. Here you do more analysis, do some research (by this I mean just google whether you can already reuse something) and build a minimal prototype to test the hypothesis. It might require coding, but even that’s not strictly necessary. You cut all the corners to be able to test it faster.</li>
<li><strong>Experiment</strong>. Only if the prototype looks promising, start thinking about designing an experiment using it. Again, you aim at testing to collect feedback from real users as fast as possible. Sometimes, even testing it on your colleagues might give you enough information.</li>
<li><strong>Productionize</strong>. Only if the experiment ends up being positive and the ROI outweighs the potential implementation and maintenance costs, start investing in productionizing your prototype and embedding it natively into the product.</li>
</ul>
</section>
<section id="optimize-time-to-value" class="level2">
<h2 class="anchored" data-anchor-id="optimize-time-to-value">Optimize time to value</h2>
<p>In the figure below, you can see that it’s possible to <strong>“short-circuit”</strong> the flow. And this, possibly, is the single most important part of it.</p>
<p>If, in the prototyping phase, either the additional analysis or the first draft shows that it doesn’t make sense to move forward? Go back and adjust your hypothesis with the new learnings. If, after the experiment phase, there is no expected uplift – no worries, just go back and tune your hypothesis.</p>
<p><img src="https://www.eliasnema.com/posts/hypothesize/time_to_value.png" class="img-fluid"></p>
<p>All of these allows us to save costs, possibly in the most expensive parts, and to <strong>improve time to value</strong>. Time to value is a commonly optimized metric that measures the length of time necessary to realize the benefits of the solution.</p>
<p>And your actual savings will be even greater than you see in the figure above, because each of the following components is potentially bigger in time investment than the previous one. Of course, it will strongly depend on the change you’re making, but generally it’s easier to create a prototype than to productionize it.</p>
<p><img src="https://www.eliasnema.com/posts/hypothesize/savings.png" class="img-fluid"></p>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>This framework doesn’t command you HOW to build your product. Instead, it guides your thinking into WHAT is the most meaningful thing to work on at any particular moment. This allows you to hedge product risks while maximizing learnings, build a common dictionary within a team and optimize time to value.</p>
<p>Since it serves only as guidance, it can also work together with scrum, radical focus or any other process you’re using. No need to break what’s already working.</p>
<p>I’m going into more details about how to generate hypotheses and about each of the steps in the book I’m working now. It’s called <strong>Hypothesize!</strong> and you can <a href="https://gumroad.com/l/SSTiNM/kwfh1gn">pre-order it now at half price</a>.</p>
<p><em>Note that you will only get charged after the release date.</em></p>


</section>

 ]]></description>
  <category>product</category>
  <category>experimentation</category>
  <guid>https://www.eliasnema.com/posts/hypothesize/hypothesize.html</guid>
  <pubDate>Sat, 23 May 2020 23:00:00 GMT</pubDate>
</item>
<item>
  <title>Unaggregate your data, bust a quote and learn a thing about modern football</title>
  <dc:creator>Elias Nema</dc:creator>
  <link>https://www.eliasnema.com/posts/man_city_stats/city_stats.html</link>
  <description><![CDATA[ 





<section id="introduction" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>Somehow I’ve spent the last week looking at Man City stats.</p>
<p>It all started with this quote in the book about the <a href="https://www.amazon.com/Football-Hackers-Science-Data-Revolution/dp/1788702050">data and football</a> that I’m reading now.</p>
<p><img src="https://www.eliasnema.com/posts/man_city_stats/quote.jpg" class="img-fluid"></p>

<div class="no-row-height column-margin column-container"><div class="">
<p><strong>Spoiler alert</strong>: this proved to be wrong. But it triggered interest from my side. Man City is one of the most recognisable sides, but do they play that short?</p>
</div></div></section>
<section id="a-common-pitfall" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="a-common-pitfall">A common pitfall</h2>
<p>So I wanted to quickly double-check the fact. Which, turned out, to be not easy at all. Available data is either not complete or too aggregated, there is a shortage of reliable publicly available sources. For example, the <a href="https://www.premierleague.com/stats/top/clubs/att_obox_goal?se=79">official premier league</a> site says that MC has scored 13 goals from outside the box during the 2017/18 season, but there is no information about distributions (the quote mentions only the first half of the season).</p>
<p>And here I fell in a very common mistake people make while working with data. It’s always tempting to look at aggregated data to see patterns and trends. However, often you need the exact opposite: take one sample, study it, see if it makes sense, see if it contains data that you expect.</p>

<div class="no-row-height column-margin column-container"><div class="">
<p>This is a great example of a very common mistake people make when working with data. It’s always tempting to look at aggregated data to see patterns and trends. However, often you need the exact opposite: take one sample, study it, see if it makes sense, see if it contains data that you expect.</p>
</div></div><p>In fact, to prove the quote wrong I needed just a single example of a goal that City has scored from outside the box during that part of the season. So after searching for the best strikes of the season on YouTube&nbsp;I found that the quote didn’t hold up. Just take a look at this last-minute <a href="https://www.youtube.com/watch?v=VVDJEVCUO3c">wonder-strike from Sterling</a>.</p>
<p>So we’ve already proved the quote wrong simply by watching a couple of great football moments.</p>
</section>
<section id="going-deeper" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="going-deeper">Going deeper</h2>
<p>But now that we are in the topic, let’s dig deeper. The best website that I was able to find to look at more granular data is <a href="https://fbref.com/">fbref</a>. There I took statistics on every shot Man City did during their last 3 Premier League seasons. We also have a distance for each shot.</p>
<section id="visualising" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="visualising">Visualising</h3>
<p>Here and below I’ll be taking into consideration only first halves of the seasons. First, because the quote was about that. Second, this would be enough to see the tactical changes over time. Third, data for the 2019/20 season is incomplete anyways.</p>
<p>Let’s start with trying to understand if there is any significant difference between seasons.</p>
<p><img src="https://www.eliasnema.com/posts/man_city_stats/histograms.png" class="img-fluid"></p>
<p>This visualisation is of little use here, but at least we can see some distinctions between seasons.</p>
<p>Let’s quickly compute t-test statistics to get a numeric representation of it:</p>
<pre><code>season 17/18 vs 18/19: Ttest_indResult(statistic=1.1348979627228202, pvalue=0.2568168035045629)
season 18/19 vs 19/20: Ttest_indResult(statistic=1.8185721011018878, pvalue=0.06943167359879912)
season 17/18 vs 19/20: Ttest_indResult(statistic=3.1215926762079387, pvalue=0.0018782472078475076)</code></pre>

<div class="no-row-height column-margin column-container"><div class="">
<p>This compounds to a huge difference from 2017 to 2019 seasons.</p>
</div></div><p>Indeed, looks like there is a small but not very significant difference between 2017 and 2018, while a much bigger difference between 2018 and 2019. This compounds to a huge difference from 2017 to 2019 seasons.</p>
<p>Let’s give this difference a better human interface.</p>
</section>
<section id="stacked-graph" class="level3">
<h3 class="anchored" data-anchor-id="stacked-graph">Stacked graph</h3>
<p>One way to look at distribution differences would be a stacked bar graph. This graph quickly falls apart when the number of dimension grows, but is perfect for our use case.</p>
<p><img src="https://www.eliasnema.com/posts/man_city_stats/stacked_graph.png" class="img-fluid"></p>
<p>It’s not too detailed, but also very concise. And we clearly see that each season City is aiming to shoot more and from the closer range.</p>
</section>
<section id="density-graphs" class="level3">
<h3 class="anchored" data-anchor-id="density-graphs">Density graphs</h3>
<p>If we want to look even closer we can go with density graphs.</p>
<p><img src="https://www.eliasnema.com/posts/man_city_stats/density.png" class="img-fluid"></p>
<p>Wow, this tells a story now. A coincidence? I doubt that.</p>
</section>
</section>
<section id="conclusion-learnings" class="level2">
<h2 class="anchored" data-anchor-id="conclusion-learnings">Conclusion &amp; learnings</h2>
<p>I believe football evolves by learning more about itself. It’s a known fact that teams have started optimising for shooting from positions with higher chance of scoring, which <a href="https://totalfootballanalysis.com/article/xg-analysis-tactical-analysis-tactics">translates into less long-ranged shots</a>.</p>
<p>Evolution of Man City from the season 2017 to 2019 shows that they indeed follow this trend of shooting from “better” positions. But does it make their game better? That’s the question we can’t objectively answer with data.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Some concise takeaways for the data folks
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>Don’t start with aggregated data. Firstly, make sure that single data points look reasonable.</li>
<li>Compare distributions numerically using the t-test, Kolmogorov-Smirnov test, etc.</li>
<li>Add a visual story by bucketing:
<ul>
<li>Histograms</li>
<li>Pivot histograms into a stacked chart for a different perspective</li>
<li>Go for density&nbsp;estimations for more details</li>
</ul></li>
</ul>
</div>
</div>
</section>
<section id="code" class="level2">
<h2 class="anchored" data-anchor-id="code">Code</h2>
<section id="reading-data" class="level3">
<h3 class="anchored" data-anchor-id="reading-data">Reading data</h3>
<div id="cell-11" class="cell" data-execution_count="27">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb2-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pandas <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> pd</span>
<span id="cb2-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> scipy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> stats</span>
<span id="cb2-4">city <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.read_csv(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'man_city_17_18_19.csv'</span>)</span></code></pre></div>
</details>
</div>
<div id="cell-12" class="cell" data-execution_count="28">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1">city.head()</span></code></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="28">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">Season</th>
<th data-quarto-table-cell-role="th">Matchday</th>
<th data-quarto-table-cell-role="th">Opponent</th>
<th data-quarto-table-cell-role="th">Minute</th>
<th data-quarto-table-cell-role="th">Player</th>
<th data-quarto-table-cell-role="th">Outcome</th>
<th data-quarto-table-cell-role="th">Distance</th>
<th data-quarto-table-cell-role="th">BodyPart</th>
<th data-quarto-table-cell-role="th">Notes</th>
<th data-quarto-table-cell-role="th">SCA1</th>
<th data-quarto-table-cell-role="th">SCA1Event</th>
<th data-quarto-table-cell-role="th">SCA2</th>
<th data-quarto-table-cell-role="th">SCA2Event</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>2017/18</td>
<td>1</td>
<td>Brighton &amp; Hove Albion</td>
<td>4</td>
<td>Gabriel Jesus</td>
<td>Blocked</td>
<td>11</td>
<td>Right Foot</td>
<td>NaN</td>
<td>Fernandinho</td>
<td>Pass (Live)</td>
<td>Kyle Walker</td>
<td>Pass (Live)</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>2017/18</td>
<td>1</td>
<td>Brighton &amp; Hove Albion</td>
<td>9</td>
<td>Danilo</td>
<td>Off Target</td>
<td>21</td>
<td>Right Foot</td>
<td>NaN</td>
<td>David Silva</td>
<td>Pass (Live)</td>
<td>Danilo</td>
<td>Pass (Live)</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>2017/18</td>
<td>1</td>
<td>Brighton &amp; Hove Albion</td>
<td>14</td>
<td>Fernandinho</td>
<td>Off Target</td>
<td>10</td>
<td>Head</td>
<td>NaN</td>
<td>David Silva</td>
<td>Pass (Dead)</td>
<td>NaN</td>
<td>NaN</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>2017/18</td>
<td>1</td>
<td>Brighton &amp; Hove Albion</td>
<td>17</td>
<td>Kevin De Bruyne</td>
<td>Saved</td>
<td>27</td>
<td>Right Foot</td>
<td>Free kick</td>
<td>David Silva</td>
<td>Fouled</td>
<td>Fernandinho</td>
<td>Pass (Live)</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>2017/18</td>
<td>1</td>
<td>Brighton &amp; Hove Albion</td>
<td>32</td>
<td>Kevin De Bruyne</td>
<td>Blocked</td>
<td>28</td>
<td>Right Foot</td>
<td>Free kick</td>
<td>David Silva</td>
<td>Fouled</td>
<td>Danilo</td>
<td>Pass (Live)</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div id="cell-13" class="cell" data-execution_count="29">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(city.Season.value_counts())</span>
<span id="cb4-2"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(city.Matchday.nunique())</span></code></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>2019/20    376
2018/19    346
2017/18    338
Name: Season, dtype: int64
19</code></pre>
</div>
</div>
<p>Data only for two halves of two seasons. Getting shots per searson.</p>
<div id="cell-15" class="cell" data-execution_count="30">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1">y17 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> city.query(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Season == '2017/18'"</span>)[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Distance'</span>]</span>
<span id="cb6-2">y18 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> city.query(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Season == '2018/19'"</span>)[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Distance'</span>]</span>
<span id="cb6-3">y19 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> city.query(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Season == '2019/20'"</span>)[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Distance'</span>]</span></code></pre></div>
</details>
</div>
</section>
<section id="comparing-two-samples" class="level3">
<h3 class="anchored" data-anchor-id="comparing-two-samples">Comparing two samples</h3>
<div id="cell-17" class="cell" data-execution_count="31">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> matplotlib <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span>
<span id="cb7-2">plt.style.use(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Solarize_Light2'</span>)</span>
<span id="cb7-3"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%</span>config InlineBackend.figure_format <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'retina'</span></span>
<span id="cb7-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> seaborn <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> sns</span>
<span id="cb7-5"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> warnings</span>
<span id="cb7-6">warnings.filterwarnings(action<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ignore'</span>)</span></code></pre></div>
</details>
</div>
<div id="cell-18" class="cell" data-execution_count="32">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1">sns.distplot(y17, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">20</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'17/18'</span>)</span>
<span id="cb8-2">sns.distplot(y18, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">20</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'18/19'</span>)</span>
<span id="cb8-3">sns.distplot(y19, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">20</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'19/20'</span>)</span>
<span id="cb8-4">plt.legend()</span></code></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://www.eliasnema.com/posts/man_city_stats/city_stats_files/figure-html/cell-7-output-1.png" width="395" height="264" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="cell-19" class="cell" data-execution_count="33">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1">y17.mean(), y17.std()</span></code></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="33">
<pre><code>(16.701183431952664, 8.51091453670634)</code></pre>
</div>
</div>
<div id="cell-20" class="cell" data-execution_count="34">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1">y18.mean(), y18.std()</span></code></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="34">
<pre><code>(15.95086705202312, 8.779779921952818)</code></pre>
</div>
</div>
<div id="cell-21" class="cell" data-execution_count="35">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1">y19.mean(), y19.std()</span></code></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="35">
<pre><code>(14.872340425531915, 6.9627336279989995)</code></pre>
</div>
</div>
<div id="cell-22" class="cell" data-execution_count="36">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># equal_var=False to perform welch's test instead, because of different variance and amount of sample</span></span>
<span id="cb15-2"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'season 17/18 vs 18/19: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>stats<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>ttest_ind(y17,y18, equal_var<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>)<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>)</span>
<span id="cb15-3"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'season 18/19 vs 19/20: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>stats<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>ttest_ind(y18,y19, equal_var<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>)<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>)</span>
<span id="cb15-4"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'season 17/18 vs 19/20: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>stats<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>ttest_ind(y17,y19, equal_var<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>)<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>)</span></code></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>season 17/18 vs 18/19: Ttest_indResult(statistic=1.1348979627228202, pvalue=0.2568168035045629)
season 18/19 vs 19/20: Ttest_indResult(statistic=1.8185721011018878, pvalue=0.06943167359879913)
season 17/18 vs 19/20: Ttest_indResult(statistic=3.1215926762079387, pvalue=0.001878247207847508)</code></pre>
</div>
</div>
<p>Looks like there is a high chance of difference between them.</p>
</section>
<section id="density-distribution" class="level3">
<h3 class="anchored" data-anchor-id="density-distribution">Density distribution</h3>
<div id="cell-25" class="cell" data-execution_count="37">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb17" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1">kde17 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> stats.gaussian_kde(y17)</span>
<span id="cb17-2">kde18 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> stats.gaussian_kde(y18)</span>
<span id="cb17-3">kde19 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> stats.gaussian_kde(y19)</span>
<span id="cb17-4">grid <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.linspace(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">50</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">51</span>)</span></code></pre></div>
</details>
</div>
<div id="cell-26" class="cell" data-execution_count="38">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1">f, axs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> plt.subplots(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>))</span>
<span id="cb18-2"></span>
<span id="cb18-3">axs[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].plot(grid, kde17(grid), label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"season 2017/18"</span>)</span>
<span id="cb18-4">axs[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].plot(grid, kde18(grid), label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"season 2018/19"</span>)</span>
<span id="cb18-5">axs[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].plot(grid, kde18(grid)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>kde17(grid), label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"difference between 2018 and 2017"</span>)</span>
<span id="cb18-6"></span>
<span id="cb18-7">axs[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>].plot(grid, kde18(grid), label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"season 2018/19"</span>)</span>
<span id="cb18-8">axs[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>].plot(grid, kde19(grid), label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"season 2019/20"</span>)</span>
<span id="cb18-9">axs[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>].plot(grid, kde19(grid)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>kde18(grid), label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"difference between 2019 and 2018"</span>)</span>
<span id="cb18-10"></span>
<span id="cb18-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># axs[2].plot(grid, kde17(grid), label="season 2017/18")</span></span>
<span id="cb18-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># axs[2].plot(grid, kde19(grid), label="season 2019/20")</span></span>
<span id="cb18-13">axs[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>].plot(grid, kde19(grid)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>kde17(grid), label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"difference between 2019 and 2017"</span>)</span>
<span id="cb18-14"></span>
<span id="cb18-15"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> ax <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> axs:</span>
<span id="cb18-16">    ax.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">set</span>(ylabel<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Density'</span>)</span>
<span id="cb18-17">    ax.legend()</span>
<span id="cb18-18"></span>
<span id="cb18-19">axs[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>].<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">set</span>(xlabel<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Shooting distance'</span>)</span>
<span id="cb18-20">plt.show()</span></code></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://www.eliasnema.com/posts/man_city_stats/city_stats_files/figure-html/cell-13-output-1.png" width="520" height="699" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="cell-27" class="cell" data-execution_count="39">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb19" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1">plot <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> plt.figure(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>))</span>
<span id="cb19-2">plt.plot(grid, kde18(grid), label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"season 2018/19"</span>, figure<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>plot)</span>
<span id="cb19-3">plt.plot(grid, kde19(grid), label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"season 2019/20"</span>, figure<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>plot)</span>
<span id="cb19-4">plt.plot(grid, kde19(grid)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>kde18(grid), label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"difference between 2019 and 2018"</span>)</span>
<span id="cb19-5">plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Shooting distance'</span>)</span>
<span id="cb19-6">plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Density'</span>)</span>
<span id="cb19-7">plt.legend()</span>
<span id="cb19-8">plt.show()</span></code></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://www.eliasnema.com/posts/man_city_stats/city_stats_files/figure-html/cell-14-output-1.png" width="514" height="213" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="cell-28" class="cell" data-execution_count="40">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb20" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1">plot <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> plt.figure(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>))</span>
<span id="cb20-2">plt.plot(grid, kde17(grid), label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"season 2017/18"</span>, figure<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>plot)</span>
<span id="cb20-3">plt.plot(grid, kde19(grid), label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"season 2019/20"</span>, figure<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>plot)</span>
<span id="cb20-4">plt.plot(grid, kde19(grid)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>kde17(grid), label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"difference between 2019 and 2017"</span>)</span>
<span id="cb20-5">plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Shooting distance'</span>)</span>
<span id="cb20-6">plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Density'</span>)</span>
<span id="cb20-7">plt.legend()</span>
<span id="cb20-8">plt.show()</span></code></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://www.eliasnema.com/posts/man_city_stats/city_stats_files/figure-html/cell-15-output-1.png" width="514" height="210" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="cell-29" class="cell" data-execution_count="41">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb21" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1">plot <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> plt.figure(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>))</span>
<span id="cb21-2">plt.plot(grid, kde18(grid)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>kde17(grid), label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"difference between 18 and 17"</span>, figure<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>plot)</span>
<span id="cb21-3">plt.plot(grid, kde19(grid)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>kde18(grid), label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"difference between 19 and 18"</span>)</span>
<span id="cb21-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># plt.plot(grid, kde19(grid)-kde17(grid), label="difference between 19 and 17")</span></span>
<span id="cb21-5">plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Shooting distance'</span>)</span>
<span id="cb21-6">plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Density'</span>)</span>
<span id="cb21-7">plt.legend()</span>
<span id="cb21-8">plt.show()</span></code></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://www.eliasnema.com/posts/man_city_stats/city_stats_files/figure-html/cell-16-output-1.png" width="527" height="209" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p>You can see the difference after plotting estimated densities.</p>
<p>Manchester City has started shooting more from the 5-10 and 15-20 yards range. They shoot less from &gt; 30 yards.</p>
<div id="cell-31" class="cell" data-execution_count="42">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb22" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1">diff<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>plt.bar(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">51</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>), </span>
<span id="cb22-2">             height<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(np.histogram(y19,bins<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">50</span>))[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> np.histogram(y17,bins<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">50</span>))[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>])</span>
<span id="cb22-3">             ) </span>
<span id="cb22-4">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"a-b"</span>)</span></code></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="42">
<pre><code>Text(0.5, 1.0, 'a-b')</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://www.eliasnema.com/posts/man_city_stats/city_stats_files/figure-html/cell-17-output-2.png" width="377" height="266" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Here is the difference between histograms.</p>
<div id="cell-33" class="cell" data-execution_count="43">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb24" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1">df<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>pd.DataFrame([</span>
<span id="cb24-2">        np.histogram(y17,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>,(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">50</span>))[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> y17.count() <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>,</span>
<span id="cb24-3">        np.histogram(y18,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>,(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">50</span>))[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> y18.count() <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>,</span>
<span id="cb24-4">        np.histogram(y19,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>,(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">50</span>))[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> y19.count() <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span></span>
<span id="cb24-5">        ], index<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'2017'</span>,<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'2018'</span>,<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'2019'</span>], columns<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'0-10'</span>,<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'10-20'</span>,<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'20-30'</span>,<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'30-40'</span>,<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'40-50'</span>])</span></code></pre></div>
</details>
</div>
<div id="cell-34" class="cell" data-execution_count="44">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb25" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1">city[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Distance bins'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>  pd.cut(city[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Distance'</span>], bins<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">20</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">30</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">40</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">50</span>])</span></code></pre></div>
</details>
</div>
<div id="cell-35" class="cell" data-execution_count="45">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb26" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1">df1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> city[[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Season'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Distance bins'</span>,<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Distance'</span>]].groupby(by<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Season'</span>,<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Distance bins'</span>],).agg(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'count'</span>).unstack()</span></code></pre></div>
</details>
</div>
<div id="cell-36" class="cell" data-execution_count="46">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb27" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1">df1.columns <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'(0, 10]'</span>,<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'(10, 20]'</span>,<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'(20, 30]'</span>,<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'(30, 40]'</span>,<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'(40, 50]'</span>]</span></code></pre></div>
</details>
</div>
<div id="cell-37" class="cell" data-execution_count="47">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb28" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1">ax <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> df1.plot(kind<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'bar'</span>, stacked<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>,width<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">.85</span>, figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>))</span>
<span id="cb28-2">ax.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">set</span>(ylabel<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'# of shots'</span>)</span>
<span id="cb28-3">ax.legend(bbox_to_anchor<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.025</span>))</span>
<span id="cb28-4"></span>
<span id="cb28-5"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i, p <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">enumerate</span>(ax.patches):</span>
<span id="cb28-6">    width, height <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> p.get_width(), p.get_height()</span>
<span id="cb28-7">    x, y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> p.get_xy()</span>
<span id="cb28-8">    pct <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> height<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>df1.iloc[i<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">//</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>].<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>()</span>
<span id="cb28-9">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> pct <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">.04</span>:</span>
<span id="cb28-10">        ax.annotate(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{:.0%}</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">format</span>(pct), (x<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">.27</span>, y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> height<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span> ), color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'white'</span>, fontsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>,)</span></code></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://www.eliasnema.com/posts/man_city_stats/city_stats_files/figure-html/cell-22-output-1.png" width="360" height="296" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="cell-38" class="cell" data-execution_count="48">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb29" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1">pd.DataFrame([(df1.loc[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'2017/18'</span>]<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>df1.loc[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'2017/18'</span>].<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>()).T,</span>
<span id="cb29-2">(df1.loc[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'2018/19'</span>]<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>df1.loc[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'2018/19'</span>].<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>()).T,</span>
<span id="cb29-3">(df1.loc[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'2019/20'</span>]<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>df1.loc[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'2019/20'</span>].<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>()).T])</span></code></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="48">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">(0, 10]</th>
<th data-quarto-table-cell-role="th">(10, 20]</th>
<th data-quarto-table-cell-role="th">(20, 30]</th>
<th data-quarto-table-cell-role="th">(30, 40]</th>
<th data-quarto-table-cell-role="th">(40, 50]</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">2017/18</td>
<td>0.281065</td>
<td>0.375740</td>
<td>0.269231</td>
<td>0.071006</td>
<td>0.002959</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">2018/19</td>
<td>0.321739</td>
<td>0.385507</td>
<td>0.240580</td>
<td>0.049275</td>
<td>0.002899</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2019/20</td>
<td>0.313830</td>
<td>0.430851</td>
<td>0.252660</td>
<td>0.002660</td>
<td>0.000000</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div id="cell-39" class="cell" data-execution_count="49">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb30" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1">df1</span></code></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="49">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">(0, 10]</th>
<th data-quarto-table-cell-role="th">(10, 20]</th>
<th data-quarto-table-cell-role="th">(20, 30]</th>
<th data-quarto-table-cell-role="th">(30, 40]</th>
<th data-quarto-table-cell-role="th">(40, 50]</th>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">Season</th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">2017/18</td>
<td>95</td>
<td>127</td>
<td>91</td>
<td>24</td>
<td>1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">2018/19</td>
<td>111</td>
<td>133</td>
<td>83</td>
<td>17</td>
<td>1</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2019/20</td>
<td>118</td>
<td>162</td>
<td>95</td>
<td>1</td>
<td>0</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>


</section>
</section>

 ]]></description>
  <category>analytics</category>
  <guid>https://www.eliasnema.com/posts/man_city_stats/city_stats.html</guid>
  <pubDate>Tue, 19 May 2020 23:00:00 GMT</pubDate>
</item>
<item>
  <title>Getting “Structured” Back to SQL</title>
  <dc:creator>Elias Nema</dc:creator>
  <link>https://www.eliasnema.com/posts/structured-sql/structured-sql.html</link>
  <description><![CDATA[ 





<section id="half-a-century-old-question" class="level1">
<h1>Half a century old question</h1>
<p>Not that many questions in computer science have been circulating for more than 50 years and are still around. <strong>“How to write SQL”</strong> is one of them.</p>
<p>There is a good reason for this.</p>
<p>Relational databases have dominated the market since the 70s. Then the whole <a href="https://en.wikipedia.org/wiki/NoSQL">NoSQL</a> movement arose and smoothly evolved into a <a href="https://en.wikipedia.org/wiki/NewSQL">NewSQL</a>. Recently, all major streaming systems are <a href="https://arxiv.org/abs/1905.12133">adding support for SQL</a>. There should be something really powerful about this language.</p>
<p>With great power, comes - you know. SQL is so flexible that allows you to write queries in almost any form and still get some results. The problem is that understanding if this result makes sense requires usually more effort than to produce it. You saw it yourself - “fixing” joins with <code>DISTINCT</code> statement, counting rows multiple times.</p>
<blockquote class="blockquote">
<p>SQL is so flexible that allows you to write queries in almost any form and still get <strong>some results</strong>. The problem is that understanding if this result makes sense <strong>requires usually more effort</strong> than to produce it.</p>
</blockquote>
<p>I argue that most of this can be avoided by writing queries in a <strong>structured manner</strong>, optimizing for readability first.</p>
</section>
<section id="structure-d-query-language" class="level1">
<h1>Structure <em>[d Query Language]</em></h1>
<p>But how to create a structure? First, begin with the end in mind. What should the answer look like? For example, <strong>you want to analyze revenue for a specific sales channel by different region</strong>. See, it’s already a prepared <code>SELECT</code> statement.</p>
<p><em>Here and below, I’ll be using pseudo-SQL to avoid unrelated details.</em></p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode sql code-with-copy"><code class="sourceCode sql"><span id="cb1-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">SELECT</span> channel, region, <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">SUM</span>(sales)</span></code></pre></div>
<p>Usually, there would be the main subject in your question. Above, you want to analyze revenue. So <code>sales</code> is going to be your main entity, <strong>a driving table</strong>. In FROM, you should always put it first.</p>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode sql code-with-copy"><code class="sourceCode sql"><span id="cb2-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">FROM</span> sales                                 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">---- driving table</span></span></code></pre></div>
<p>Now you want to filter for a specific channel. For this, go to the new table - channels. When adding it, think of your query as a tree - the main table as a body and the new table as a branch.</p>
<div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode sql code-with-copy"><code class="sourceCode sql"><span id="cb3-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">FROM</span> sales                                 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">---- driving table</span></span>
<span id="cb3-2"></span>
<span id="cb3-3">  <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">JOIN</span> channels <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">ON</span> channel <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'web'</span>         <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">---- branch 1</span></span></code></pre></div>
<blockquote class="blockquote">
<p>One thing to keep in mind when adding tables is the granularity you are operating on. The last thing you want is to introduce a row explosion when joining. <strong>Write your join conditions carefully.</strong></p>
</blockquote>
<p>The next step is to group results by region. In the sales table, there is only a <code>district_id</code>. For a region you need to go to <code>districts -&gt; cities -&gt; regions</code> tables. Hear your branch would consist of multiple tables.</p>
<div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode sql code-with-copy"><code class="sourceCode sql"><span id="cb4-1">  <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">JOIN</span> districts                           <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">---- branch 2.1</span></span>
<span id="cb4-2">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">JOIN</span> cities                            <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">---- branch 2.2</span></span>
<span id="cb4-3">      <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">JOIN</span> regions                         <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">---- branch 2.3</span></span></code></pre></div>
<p>Another way to think about this: I need to get the name of a region for each district. Basically, <code>district_id, region_name</code> with the join condition on <code>district_id</code>. It’s always good to double-check the join condition with a simple query like:</p>
<div class="sourceCode" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode sql code-with-copy"><code class="sourceCode sql"><span id="cb5-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">SELECT</span> district_id, <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">count</span>(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>)</span>
<span id="cb5-2"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">FROM</span> (district_region_branch)   <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">---  branch 2 from the previous query</span></span>
<span id="cb5-3"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">GROUP</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">BY</span> district_id</span>
<span id="cb5-4"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">HAVING</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">count</span>(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span></code></pre></div>
<p>This will check if you have duplicates on the join key. Ideally, you will do this check for every branch introduced.</p>
<p>Branching metaphor also helps with rules for <code>OUTER</code> joins - whenever introduced, carry it over for all the join conditions till the end of the current branch. If there are data inconsistencies and some cities are not available in the <code>city</code> table. Hence you introduce a <code>LEFT JOIN</code> and carry it:</p>
<div class="sourceCode" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode sql code-with-copy"><code class="sourceCode sql"><span id="cb6-1">  <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">JOIN</span> districts                           <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">---- branch</span></span>
<span id="cb6-2">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">LEFT</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">JOIN</span> cities                       <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">---- if outer join here</span></span>
<span id="cb6-3">      <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">LEFT</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">JOIN</span> regions                    <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">---- then also here</span></span></code></pre></div>
<p>Ok, so what do we have at the end?</p>
<div class="sourceCode" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode sql code-with-copy"><code class="sourceCode sql"><span id="cb7-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">SELECT</span> region, <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">SUM</span>(sales)</span>
<span id="cb7-2"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">FROM</span> sales                                 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">---- driving table</span></span>
<span id="cb7-3"></span>
<span id="cb7-4">  <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">JOIN</span> channels <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">WHERE</span> channel <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'web'</span>      <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">---- branch 1</span></span>
<span id="cb7-5"></span>
<span id="cb7-6">  <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">JOIN</span> districts                           <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">---- branch 2.1</span></span>
<span id="cb7-7">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">LEFT</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">JOIN</span> cities                       <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">---- branch 2.2</span></span>
<span id="cb7-8">      <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">LEFT</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">JOIN</span> regions                    <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">---- branch 2.3</span></span>
<span id="cb7-9"></span>
<span id="cb7-10"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">GROUP</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">BY</span> region</span></code></pre></div>
<p>Note how indentation makes the query structure more readable and puts all tables in purposeful groups.</p>
</section>
<section id="conclusion-and-a-recipe" class="level1">
<h1>Conclusion and a recipe</h1>
<p>Of course, we looked at quite a simple query. And SQL is <a href="https://en.wikipedia.org/wiki/SQL:2016">sophisticated nowadays</a>. You can do a JSON, pattern recognition, complex aggregations. However, the structure should come first. Here is how to enforce it:</p>
<blockquote class="blockquote">
<ol type="1">
<li><p><strong>Begin with the end in mind.</strong> Think about how your answer should look like.</p></li>
<li><p><strong>Find the main subject.</strong> Always put it to a FROM first. If there is more than one - wrap each into a CTE and apply these steps to each of them.</p></li>
<li><p>Add tables to the main <strong>one intent at a time.</strong> E.g.: “<em>all the following JOINs are here to get a region for a sale</em>”.</p></li>
<li><p>Be very careful about your joins. Ensure the table you add has <strong>not more than one row per join condition</strong>.</p></li>
<li><p>Move to <strong>grouping, analytical functions, etc. only after</strong> you’ve finished connecting all the data sources.</p></li>
</ol>
</blockquote>
<p>Once you have learned how to get the data you need from different sources and documented it in the form of a readable structure, the query will <strong>tell a story of your analysis</strong> in itself. More importantly, it will help others to better understand your intents and trust your results.</p>


</section>

 ]]></description>
  <category>analytics</category>
  <category>sql</category>
  <guid>https://www.eliasnema.com/posts/structured-sql/structured-sql.html</guid>
  <pubDate>Tue, 27 Aug 2019 23:00:00 GMT</pubDate>
</item>
</channel>
</rss>
